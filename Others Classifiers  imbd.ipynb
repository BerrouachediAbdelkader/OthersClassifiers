{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GcForeest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/imbd.json\")   \n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-21 23:56:31,242][cascade_classifier.fit_transform] X_groups_train.shape=[(25000, 500)],y_train.shape=(25000,),X_groups_test.shape=[(25000, 500)],y_test.shape=(25000,)\n",
      "[ 2018-04-21 23:56:31,288][cascade_classifier.fit_transform] group_dims=[500]\n",
      "[ 2018-04-21 23:56:31,290][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-04-21 23:56:31,291][cascade_classifier.fit_transform] group_ends=[500]\n",
      "[ 2018-04-21 23:56:31,293][cascade_classifier.fit_transform] X_train.shape=(25000, 500),X_test.shape=(25000, 500)\n",
      "[ 2018-04-21 23:56:31,368][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(25000, 500), X_cur_test.shape=(25000, 500)\n",
      "[ 2018-04-21 23:56:33,518][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=54.52%\n",
      "[ 2018-04-21 23:56:35,089][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=53.08%\n",
      "[ 2018-04-21 23:56:38,441][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=53.12%\n",
      "[ 2018-04-21 23:56:40,961][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=55.08%\n",
      "[ 2018-04-21 23:56:43,098][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=53.40%\n",
      "[ 2018-04-21 23:56:44,823][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=54.96%\n",
      "[ 2018-04-21 23:56:48,005][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=55.40%\n",
      "[ 2018-04-21 23:56:50,137][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=54.60%\n",
      "[ 2018-04-21 23:56:52,392][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=53.28%\n",
      "[ 2018-04-21 23:56:54,001][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=55.28%\n",
      "[ 2018-04-21 23:56:54,191][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=54.27%\n",
      "[ 2018-04-21 23:56:54,194][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=55.00%\n",
      "[ 2018-04-21 23:56:57,757][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=52.20%\n",
      "[ 2018-04-21 23:57:00,636][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=51.60%\n",
      "[ 2018-04-21 23:57:02,667][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=51.52%\n",
      "[ 2018-04-21 23:57:06,675][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=53.28%\n",
      "[ 2018-04-21 23:57:09,236][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=53.28%\n",
      "[ 2018-04-21 23:57:11,444][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=50.80%\n",
      "[ 2018-04-21 23:57:13,439][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=51.36%\n",
      "[ 2018-04-21 23:57:16,886][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=52.72%\n",
      "[ 2018-04-21 23:57:19,388][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=52.56%\n",
      "[ 2018-04-21 23:57:20,986][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=52.80%\n",
      "[ 2018-04-21 23:57:21,140][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=52.21%\n",
      "[ 2018-04-21 23:57:21,143][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=52.94%\n",
      "[ 2018-04-21 23:57:47,441][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=49.48%\n",
      "[ 2018-04-21 23:58:07,809][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=50.28%\n",
      "[ 2018-04-21 23:58:30,170][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=52.04%\n",
      "[ 2018-04-21 23:58:52,544][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=51.44%\n",
      "[ 2018-04-21 23:59:19,350][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=52.04%\n",
      "[ 2018-04-21 23:59:42,881][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=50.80%\n",
      "[ 2018-04-22 00:00:09,409][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=49.56%\n",
      "[ 2018-04-22 00:00:39,831][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=51.32%\n",
      "[ 2018-04-22 00:01:10,183][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=50.68%\n",
      "[ 2018-04-22 00:01:35,297][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=52.16%\n",
      "[ 2018-04-22 00:01:35,321][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=50.98%\n",
      "[ 2018-04-22 00:01:35,327][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=50.91%\n",
      "[ 2018-04-22 00:01:35,336][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=53.05%\n",
      "[ 2018-04-22 00:01:35,342][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=53.13%\n",
      "[ 2018-04-22 00:01:35,437][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(25000, 506), X_cur_test.shape=(25000, 506)\n",
      "[ 2018-04-22 00:01:37,471][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=56.12%\n",
      "[ 2018-04-22 00:01:39,914][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=50.88%\n",
      "[ 2018-04-22 00:01:41,492][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=51.68%\n",
      "[ 2018-04-22 00:01:43,420][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=50.84%\n",
      "[ 2018-04-22 00:01:46,420][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=51.80%\n",
      "[ 2018-04-22 00:01:48,787][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=53.20%\n",
      "[ 2018-04-22 00:01:50,574][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=53.28%\n",
      "[ 2018-04-22 00:01:52,181][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=55.24%\n",
      "[ 2018-04-22 00:01:55,449][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=54.96%\n",
      "[ 2018-04-22 00:01:57,727][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=53.64%\n",
      "[ 2018-04-22 00:01:57,886][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=53.16%\n",
      "[ 2018-04-22 00:01:57,888][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=54.96%\n",
      "[ 2018-04-22 00:01:59,844][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=51.84%\n",
      "[ 2018-04-22 00:02:01,698][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=52.48%\n",
      "[ 2018-04-22 00:02:05,708][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=53.16%\n",
      "[ 2018-04-22 00:02:08,332][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=52.64%\n",
      "[ 2018-04-22 00:02:10,140][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=51.16%\n",
      "[ 2018-04-22 00:02:13,517][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=54.64%\n",
      "[ 2018-04-22 00:02:16,338][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=51.48%\n",
      "[ 2018-04-22 00:02:18,613][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=54.24%\n",
      "[ 2018-04-22 00:02:20,322][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=52.48%\n",
      "[ 2018-04-22 00:02:23,992][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=51.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-22 00:02:24,287][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=52.52%\n",
      "[ 2018-04-22 00:02:24,290][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=53.45%\n",
      "[ 2018-04-22 00:03:05,247][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=59.52%\n",
      "[ 2018-04-22 00:03:46,241][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=56.40%\n",
      "[ 2018-04-22 00:04:27,843][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=55.40%\n",
      "[ 2018-04-22 00:05:08,530][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=55.52%\n",
      "[ 2018-04-22 00:05:49,018][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=56.52%\n",
      "[ 2018-04-22 00:06:28,532][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=55.32%\n",
      "[ 2018-04-22 00:07:07,860][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=54.68%\n",
      "[ 2018-04-22 00:07:48,282][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=53.52%\n",
      "[ 2018-04-22 00:08:28,480][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=56.44%\n",
      "[ 2018-04-22 00:09:09,272][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=57.36%\n",
      "[ 2018-04-22 00:09:09,310][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=56.07%\n",
      "[ 2018-04-22 00:09:09,315][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=52.47%\n",
      "[ 2018-04-22 00:09:09,321][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=55.80%\n",
      "[ 2018-04-22 00:09:09,326][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=53.79%\n",
      "[ 2018-04-22 00:09:09,441][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(25000, 506), X_cur_test.shape=(25000, 506)\n",
      "[ 2018-04-22 00:09:11,972][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=54.28%\n",
      "[ 2018-04-22 00:09:14,180][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=55.40%\n",
      "[ 2018-04-22 00:09:15,798][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=54.32%\n",
      "[ 2018-04-22 00:09:17,535][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=55.20%\n",
      "[ 2018-04-22 00:09:21,130][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=54.44%\n",
      "[ 2018-04-22 00:09:23,521][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=54.92%\n",
      "[ 2018-04-22 00:09:25,160][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=55.48%\n",
      "[ 2018-04-22 00:09:28,068][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=55.44%\n",
      "[ 2018-04-22 00:09:31,353][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=54.40%\n",
      "[ 2018-04-22 00:09:33,493][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=58.40%\n",
      "[ 2018-04-22 00:09:33,664][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=55.23%\n",
      "[ 2018-04-22 00:09:33,666][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=54.22%\n",
      "[ 2018-04-22 00:09:36,789][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=53.52%\n",
      "[ 2018-04-22 00:09:39,045][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=53.08%\n",
      "[ 2018-04-22 00:09:41,672][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=53.48%\n",
      "[ 2018-04-22 00:09:43,361][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=54.40%\n",
      "[ 2018-04-22 00:09:47,536][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=52.28%\n",
      "[ 2018-04-22 00:09:50,290][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=55.00%\n",
      "[ 2018-04-22 00:09:51,876][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=54.60%\n",
      "[ 2018-04-22 00:09:55,628][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=55.36%\n",
      "[ 2018-04-22 00:09:58,544][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=52.84%\n",
      "[ 2018-04-22 00:10:00,318][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=53.00%\n",
      "[ 2018-04-22 00:10:00,480][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=53.76%\n",
      "[ 2018-04-22 00:10:00,483][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=52.82%\n",
      "[ 2018-04-22 00:10:34,807][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=51.72%\n",
      "[ 2018-04-22 00:11:11,094][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=52.56%\n",
      "[ 2018-04-22 00:11:45,046][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=51.44%\n",
      "[ 2018-04-22 00:12:19,641][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=53.12%\n",
      "[ 2018-04-22 00:13:00,261][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=52.84%\n",
      "[ 2018-04-22 00:13:38,005][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=52.28%\n",
      "[ 2018-04-22 00:14:18,025][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=52.92%\n",
      "[ 2018-04-22 00:14:57,500][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=52.24%\n",
      "[ 2018-04-22 00:15:33,386][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=51.64%\n",
      "[ 2018-04-22 00:16:06,864][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=51.04%\n",
      "[ 2018-04-22 00:16:06,887][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=52.18%\n",
      "[ 2018-04-22 00:16:06,890][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=52.95%\n",
      "[ 2018-04-22 00:16:06,893][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=54.48%\n",
      "[ 2018-04-22 00:16:06,895][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=53.31%\n",
      "[ 2018-04-22 00:16:06,986][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(25000, 506), X_cur_test.shape=(25000, 506)\n",
      "[ 2018-04-22 00:16:08,762][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=54.56%\n",
      "[ 2018-04-22 00:16:11,934][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=55.52%\n",
      "[ 2018-04-22 00:16:14,784][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=53.28%\n",
      "[ 2018-04-22 00:16:16,404][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=53.28%\n",
      "[ 2018-04-22 00:16:17,892][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=56.24%\n",
      "[ 2018-04-22 00:16:21,119][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=54.64%\n",
      "[ 2018-04-22 00:16:23,276][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=54.52%\n",
      "[ 2018-04-22 00:16:25,582][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=53.72%\n",
      "[ 2018-04-22 00:16:27,622][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=55.08%\n",
      "[ 2018-04-22 00:16:30,771][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=54.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-22 00:16:31,530][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=54.52%\n",
      "[ 2018-04-22 00:16:31,533][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=54.74%\n",
      "[ 2018-04-22 00:16:33,880][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=53.84%\n",
      "[ 2018-04-22 00:16:35,886][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=52.96%\n",
      "[ 2018-04-22 00:16:39,725][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=53.52%\n",
      "[ 2018-04-22 00:16:42,283][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=53.40%\n",
      "[ 2018-04-22 00:16:44,564][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=51.48%\n",
      "[ 2018-04-22 00:16:46,279][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=51.52%\n",
      "[ 2018-04-22 00:16:50,334][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=53.80%\n",
      "[ 2018-04-22 00:16:53,132][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=53.00%\n",
      "[ 2018-04-22 00:16:54,691][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=53.68%\n",
      "[ 2018-04-22 00:16:58,479][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=54.20%\n",
      "[ 2018-04-22 00:16:58,743][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=53.14%\n",
      "[ 2018-04-22 00:16:58,745][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=53.27%\n",
      "[ 2018-04-22 00:17:39,301][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=53.92%\n",
      "[ 2018-04-22 00:18:19,209][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=54.48%\n",
      "[ 2018-04-22 00:18:59,151][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=54.84%\n",
      "[ 2018-04-22 00:19:39,405][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=53.80%\n",
      "[ 2018-04-22 00:20:20,196][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=56.60%\n",
      "[ 2018-04-22 00:21:00,642][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=54.88%\n",
      "[ 2018-04-22 00:21:37,805][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=55.48%\n",
      "[ 2018-04-22 00:22:17,736][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=54.72%\n",
      "[ 2018-04-22 00:22:57,831][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=54.68%\n",
      "[ 2018-04-22 00:23:37,928][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=56.92%\n",
      "[ 2018-04-22 00:23:37,947][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=55.03%\n",
      "[ 2018-04-22 00:23:37,949][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=51.92%\n",
      "[ 2018-04-22 00:23:37,952][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=55.88%\n",
      "[ 2018-04-22 00:23:37,953][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=53.42%\n",
      "[ 2018-04-22 00:23:38,034][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(25000, 506), X_cur_test.shape=(25000, 506)\n",
      "[ 2018-04-22 00:23:39,581][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_0.predict)=54.16%\n",
      "[ 2018-04-22 00:23:43,030][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_1.predict)=55.08%\n",
      "[ 2018-04-22 00:23:45,103][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_2.predict)=53.56%\n",
      "[ 2018-04-22 00:23:46,970][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_3.predict)=53.56%\n",
      "[ 2018-04-22 00:23:48,436][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_4.predict)=56.00%\n",
      "[ 2018-04-22 00:23:51,201][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_5.predict)=53.40%\n",
      "[ 2018-04-22 00:23:54,459][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_6.predict)=54.40%\n",
      "[ 2018-04-22 00:23:56,339][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_7.predict)=55.56%\n",
      "[ 2018-04-22 00:23:57,941][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_8.predict)=54.60%\n",
      "[ 2018-04-22 00:24:01,220][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_9.predict)=55.04%\n",
      "[ 2018-04-22 00:24:01,571][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_cv.predict)=54.54%\n",
      "[ 2018-04-22 00:24:01,574][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.test.predict)=54.28%\n",
      "[ 2018-04-22 00:24:03,738][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_0.predict)=53.48%\n",
      "[ 2018-04-22 00:24:05,913][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_1.predict)=52.56%\n",
      "[ 2018-04-22 00:24:07,547][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_2.predict)=52.80%\n",
      "[ 2018-04-22 00:24:11,237][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_3.predict)=54.36%\n",
      "[ 2018-04-22 00:24:13,259][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_4.predict)=53.96%\n",
      "[ 2018-04-22 00:24:15,734][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_5.predict)=53.16%\n",
      "[ 2018-04-22 00:24:17,490][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_6.predict)=53.40%\n",
      "[ 2018-04-22 00:24:21,169][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_7.predict)=53.64%\n",
      "[ 2018-04-22 00:24:23,942][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_8.predict)=54.80%\n",
      "[ 2018-04-22 00:24:25,846][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_9.predict)=53.40%\n",
      "[ 2018-04-22 00:24:26,001][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_cv.predict)=53.56%\n",
      "[ 2018-04-22 00:24:26,002][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.test.predict)=53.02%\n",
      "[ 2018-04-22 00:25:03,772][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_0.predict)=52.84%\n",
      "[ 2018-04-22 00:25:43,728][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_1.predict)=53.68%\n",
      "[ 2018-04-22 00:26:20,867][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_2.predict)=54.32%\n",
      "[ 2018-04-22 00:26:53,479][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_3.predict)=50.60%\n",
      "[ 2018-04-22 00:27:25,496][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_4.predict)=54.84%\n",
      "[ 2018-04-22 00:28:03,379][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_5.predict)=51.76%\n",
      "[ 2018-04-22 00:28:40,279][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_6.predict)=50.84%\n",
      "[ 2018-04-22 00:29:17,386][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_7.predict)=51.24%\n",
      "[ 2018-04-22 00:29:48,625][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_8.predict)=51.96%\n",
      "[ 2018-04-22 00:30:23,442][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_9.predict)=53.20%\n",
      "[ 2018-04-22 00:30:23,462][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_cv.predict)=52.53%\n",
      "[ 2018-04-22 00:30:23,465][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.test.predict)=52.86%\n",
      "[ 2018-04-22 00:30:23,469][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=54.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-22 00:30:23,470][cascade_classifier.calc_accuracy] Accuracy(layer_4 - test.classifier_average)=53.56%\n",
      "[ 2018-04-22 00:30:23,555][cascade_classifier.fit_transform] [layer=5] look_indexs=[0], X_cur_train.shape=(25000, 506), X_cur_test.shape=(25000, 506)\n",
      "[ 2018-04-22 00:30:25,504][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_0.predict)=53.88%\n",
      "[ 2018-04-22 00:30:27,009][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_1.predict)=52.20%\n",
      "[ 2018-04-22 00:30:29,698][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_2.predict)=53.56%\n",
      "[ 2018-04-22 00:30:32,255][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_3.predict)=55.52%\n",
      "[ 2018-04-22 00:30:34,690][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_4.predict)=53.00%\n",
      "[ 2018-04-22 00:30:36,528][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_5.predict)=52.88%\n",
      "[ 2018-04-22 00:30:39,350][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_6.predict)=54.12%\n",
      "[ 2018-04-22 00:30:41,688][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_7.predict)=55.44%\n",
      "[ 2018-04-22 00:30:44,049][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_8.predict)=54.72%\n",
      "[ 2018-04-22 00:30:46,051][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_9.predict)=54.76%\n",
      "[ 2018-04-22 00:30:46,234][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_cv.predict)=54.01%\n",
      "[ 2018-04-22 00:30:46,235][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.test.predict)=54.76%\n",
      "[ 2018-04-22 00:30:49,073][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_0.predict)=53.80%\n",
      "[ 2018-04-22 00:30:51,553][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_1.predict)=52.96%\n",
      "[ 2018-04-22 00:30:54,081][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_2.predict)=52.36%\n",
      "[ 2018-04-22 00:30:55,767][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_3.predict)=53.88%\n",
      "[ 2018-04-22 00:30:58,822][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_4.predict)=52.96%\n",
      "[ 2018-04-22 00:31:02,072][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_5.predict)=51.48%\n",
      "[ 2018-04-22 00:31:04,270][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_6.predict)=53.72%\n",
      "[ 2018-04-22 00:31:06,176][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_7.predict)=52.40%\n",
      "[ 2018-04-22 00:31:10,586][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_8.predict)=52.24%\n",
      "[ 2018-04-22 00:31:12,889][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_9.predict)=52.68%\n",
      "[ 2018-04-22 00:31:13,185][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_cv.predict)=52.85%\n",
      "[ 2018-04-22 00:31:13,186][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.test.predict)=53.07%\n",
      "[ 2018-04-22 00:31:54,453][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_0.predict)=55.00%\n",
      "[ 2018-04-22 00:32:38,089][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_1.predict)=53.40%\n",
      "[ 2018-04-22 00:33:17,990][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_2.predict)=54.04%\n",
      "[ 2018-04-22 00:33:58,365][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_3.predict)=53.16%\n",
      "[ 2018-04-22 00:34:38,393][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_4.predict)=55.32%\n",
      "[ 2018-04-22 00:35:20,669][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_5.predict)=54.92%\n",
      "[ 2018-04-22 00:36:01,670][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_6.predict)=54.20%\n",
      "[ 2018-04-22 00:36:42,748][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_7.predict)=54.92%\n",
      "[ 2018-04-22 00:37:22,561][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_8.predict)=53.16%\n",
      "[ 2018-04-22 00:38:05,121][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_9.predict)=53.64%\n",
      "[ 2018-04-22 00:38:05,142][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_cv.predict)=54.18%\n",
      "[ 2018-04-22 00:38:05,144][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.test.predict)=51.66%\n",
      "[ 2018-04-22 00:38:05,148][cascade_classifier.calc_accuracy] Accuracy(layer_5 - train.classifier_average)=54.84%\n",
      "[ 2018-04-22 00:38:05,149][cascade_classifier.calc_accuracy] Accuracy(layer_5 - test.classifier_average)=53.45%\n",
      "[ 2018-04-22 00:38:05,232][cascade_classifier.fit_transform] [layer=6] look_indexs=[0], X_cur_train.shape=(25000, 506), X_cur_test.shape=(25000, 506)\n",
      "[ 2018-04-22 00:38:06,598][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_0.predict)=54.76%\n",
      "[ 2018-04-22 00:38:09,982][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_1.predict)=53.24%\n",
      "[ 2018-04-22 00:38:12,234][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_2.predict)=54.24%\n",
      "[ 2018-04-22 00:38:14,315][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_3.predict)=54.92%\n",
      "[ 2018-04-22 00:38:16,087][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_4.predict)=55.52%\n",
      "[ 2018-04-22 00:38:19,495][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_5.predict)=52.72%\n",
      "[ 2018-04-22 00:38:22,030][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_6.predict)=54.36%\n",
      "[ 2018-04-22 00:38:23,693][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_7.predict)=54.76%\n",
      "[ 2018-04-22 00:38:26,705][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_8.predict)=54.96%\n",
      "[ 2018-04-22 00:38:29,488][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_9.predict)=53.00%\n",
      "[ 2018-04-22 00:38:29,863][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_cv.predict)=54.25%\n",
      "[ 2018-04-22 00:38:29,864][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.test.predict)=54.48%\n",
      "[ 2018-04-22 00:38:31,923][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_0.predict)=51.52%\n",
      "[ 2018-04-22 00:38:33,862][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_1.predict)=53.52%\n",
      "[ 2018-04-22 00:38:37,458][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_2.predict)=53.96%\n",
      "[ 2018-04-22 00:38:39,996][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_3.predict)=52.20%\n",
      "[ 2018-04-22 00:38:41,777][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_4.predict)=52.04%\n",
      "[ 2018-04-22 00:38:45,143][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_5.predict)=53.04%\n",
      "[ 2018-04-22 00:38:47,224][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_6.predict)=54.56%\n",
      "[ 2018-04-22 00:38:49,757][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_7.predict)=52.28%\n",
      "[ 2018-04-22 00:38:51,413][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_8.predict)=54.96%\n",
      "[ 2018-04-22 00:38:55,636][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_9.predict)=53.12%\n",
      "[ 2018-04-22 00:38:56,040][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_cv.predict)=53.12%\n",
      "[ 2018-04-22 00:38:56,043][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.test.predict)=53.37%\n",
      "[ 2018-04-22 00:39:34,857][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_0.predict)=50.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-22 00:40:12,581][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_1.predict)=52.16%\n",
      "[ 2018-04-22 00:40:48,281][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_2.predict)=52.52%\n",
      "[ 2018-04-22 00:41:27,536][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_3.predict)=53.00%\n",
      "[ 2018-04-22 00:42:01,393][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_4.predict)=51.88%\n",
      "[ 2018-04-22 00:42:32,294][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_5.predict)=51.24%\n",
      "[ 2018-04-22 00:43:06,468][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_6.predict)=51.76%\n",
      "[ 2018-04-22 00:43:44,362][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_7.predict)=53.52%\n",
      "[ 2018-04-22 00:44:23,941][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_8.predict)=53.96%\n",
      "[ 2018-04-22 00:44:59,041][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_9.predict)=53.00%\n",
      "[ 2018-04-22 00:44:59,114][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_cv.predict)=52.32%\n",
      "[ 2018-04-22 00:44:59,125][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.test.predict)=52.44%\n",
      "[ 2018-04-22 00:44:59,131][cascade_classifier.calc_accuracy] Accuracy(layer_6 - train.classifier_average)=53.74%\n",
      "[ 2018-04-22 00:44:59,137][cascade_classifier.calc_accuracy] Accuracy(layer_6 - test.classifier_average)=53.41%\n",
      "[ 2018-04-22 00:44:59,143][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=4, accuracy_train=55.88%, accuracy_test=53.42%\n"
     ]
    }
   ],
   "source": [
    "    # X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-22 03:30:50,752][cascade_classifier.transform] X_groups_test.shape=[(25000, 500)]\n",
      "[ 2018-04-22 03:30:50,793][cascade_classifier.transform] group_dims=[500]\n",
      "[ 2018-04-22 03:30:50,794][cascade_classifier.transform] X_test.shape=(25000, 500)\n",
      "[ 2018-04-22 03:30:50,827][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(25000, 500)\n",
      "[ 2018-04-22 03:31:01,176][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(25000, 506)\n",
      "[ 2018-04-22 03:31:09,147][cascade_classifier.transform] [layer=2] look_indexs=[0], X_cur_test.shape=(25000, 506)\n",
      "[ 2018-04-22 03:31:18,347][cascade_classifier.transform] [layer=3] look_indexs=[0], X_cur_test.shape=(25000, 506)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 53.420000 %\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5059     \n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6907 - acc: 0.5286     \n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6870 - acc: 0.5480     \n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6779 - acc: 0.5642     \n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6594 - acc: 0.5982     \n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6395 - acc: 0.6161     \n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6167 - acc: 0.6425     \n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5968 - acc: 0.6549     \n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5796 - acc: 0.6672     \n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5660 - acc: 0.6814     \n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5557 - acc: 0.6890     \n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5461 - acc: 0.6974     \n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5379 - acc: 0.7023     \n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5281 - acc: 0.7103     \n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5213 - acc: 0.7129     \n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5165 - acc: 0.7164     \n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5120 - acc: 0.7165     - ETA:\n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5059 - acc: 0.7191     \n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5029 - acc: 0.7226     \n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4989 - acc: 0.7241     \n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4937 - acc: 0.7278     \n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4901 - acc: 0.7284     \n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4838 - acc: 0.7342     \n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4828 - acc: 0.7342     \n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4799 - acc: 0.7356     \n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4772 - acc: 0.7396     \n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4747 - acc: 0.7380     \n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4705 - acc: 0.7410     \n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4722 - acc: 0.7405     \n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4666 - acc: 0.7401     \n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4640 - acc: 0.7404     \n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4642 - acc: 0.7424     \n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4614 - acc: 0.7418     \n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4613 - acc: 0.7440     \n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4564 - acc: 0.7447     \n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4595 - acc: 0.7442     \n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4521 - acc: 0.7475     \n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4506 - acc: 0.7473     \n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4495 - acc: 0.7518     \n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4501 - acc: 0.7504     \n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4460 - acc: 0.7491     \n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4464 - acc: 0.7497     \n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4459 - acc: 0.7513     \n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4449 - acc: 0.7503     \n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4429 - acc: 0.7505     \n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4418 - acc: 0.7506     \n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4374 - acc: 0.7541     \n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4357 - acc: 0.7547     \n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4377 - acc: 0.7554     \n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4355 - acc: 0.7556     \n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4330 - acc: 0.7553     \n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4328 - acc: 0.7567     \n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4330 - acc: 0.7556     \n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4295 - acc: 0.7558     \n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4285 - acc: 0.7584     \n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4294 - acc: 0.7596     - ETA: 1s -\n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4290 - acc: 0.7579     \n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4222 - acc: 0.7605     \n",
      "Epoch 59/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4246 - acc: 0.7608     \n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4219 - acc: 0.7622     \n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4277 - acc: 0.7598     \n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4223 - acc: 0.7624     \n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4224 - acc: 0.7621     \n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4190 - acc: 0.7621     \n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4164 - acc: 0.7638     \n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4170 - acc: 0.7640     \n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4196 - acc: 0.7639     \n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4188 - acc: 0.7647     \n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4162 - acc: 0.7639     \n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4180 - acc: 0.7649     \n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4098 - acc: 0.7671     \n",
      "Epoch 72/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4137 - acc: 0.7660     \n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4168 - acc: 0.7652     \n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4120 - acc: 0.7650     \n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4073 - acc: 0.7688     \n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4129 - acc: 0.7653     \n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4136 - acc: 0.7659     \n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4084 - acc: 0.7676     \n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4102 - acc: 0.7662     \n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4076 - acc: 0.7666     \n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4081 - acc: 0.7681     \n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4064 - acc: 0.7682     \n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4056 - acc: 0.7679     \n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4088 - acc: 0.7668     \n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.4027 - acc: 0.7691     \n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4058 - acc: 0.7669     \n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4056 - acc: 0.7670     \n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4052 - acc: 0.7668     \n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4010 - acc: 0.7697     \n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3987 - acc: 0.7702     \n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4026 - acc: 0.7688     \n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3986 - acc: 0.7708     \n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4023 - acc: 0.7680     \n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4024 - acc: 0.7697     \n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4014 - acc: 0.7702     \n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3943 - acc: 0.7732     \n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3936 - acc: 0.7728     \n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3977 - acc: 0.7709     \n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3982 - acc: 0.7725     \n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - ETA: 0s - loss: 0.3946 - acc: 0.772 - 1s - loss: 0.3941 - acc: 0.7727     \n",
      "1920/2500 [======================>.......] - ETA: 0sEpoch 1/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4983     \n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4962     \n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5001     \n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4956     \n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4921     \n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4989     \n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5014     \n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4998     \n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4984     \n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4982     \n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5019     \n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4972     \n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4991     \n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4985     \n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4932     \n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4986     \n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4908     \n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4995     \n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4964     \n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5000     \n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4950     \n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4996     \n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4991     \n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4989     \n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5013     \n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6931 - acc: 0.5037     \n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4958     \n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4965     \n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5008     \n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4972     \n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4972     \n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5009     \n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5004     \n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4969     \n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4963     \n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4980     \n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4994     \n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4935     \n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4937     \n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4950     \n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4978     \n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4938     \n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5015     \n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4954     \n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4956     \n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4974     \n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4952     \n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5021     \n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5006     \n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4979     \n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4964     \n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4972     \n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4943     \n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4996     \n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4976     \n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4979     \n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6931 - acc: 0.5052     \n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6932 - acc: 0.4991     \n",
      "Epoch 59/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4992     \n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4941     \n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5027     \n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4970     \n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4980     \n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4971     \n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4934     \n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4939     \n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4996     \n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4996     \n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4948     \n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5033     \n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4988     \n",
      "Epoch 72/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4988     \n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5001     \n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4972     \n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4964     \n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4927     \n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4996     \n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4988     \n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4989     \n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5013     \n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4987     \n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4954     \n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4947     \n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5000     \n",
      "Epoch 85/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4940     \n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6932 - acc: 0.5012     \n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4949     \n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4990     \n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4986     \n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4989     \n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4990     \n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5044     \n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4984     \n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4948     \n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4975     \n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4951     \n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4997     \n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4942     \n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5015     \n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5002     \n",
      "1728/2500 [===================>..........] - ETA: 0sEpoch 1/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6933 - acc: 0.4933     \n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6929 - acc: 0.5084     \n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6919 - acc: 0.5240     \n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6892 - acc: 0.5350     \n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6823 - acc: 0.5519     \n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6703 - acc: 0.5793     \n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6564 - acc: 0.5972     \n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6376 - acc: 0.6181     \n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6198 - acc: 0.6390     \n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6028 - acc: 0.6561     \n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5869 - acc: 0.6698     \n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5765 - acc: 0.6793     \n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5645 - acc: 0.6894     \n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5551 - acc: 0.6984     \n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5471 - acc: 0.7030     \n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5380 - acc: 0.7142     \n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5307 - acc: 0.7160     \n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5240 - acc: 0.7208     \n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5203 - acc: 0.7260     \n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5158 - acc: 0.7270     \n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5124 - acc: 0.7296     \n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5076 - acc: 0.7347     \n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5061 - acc: 0.7353     \n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5013 - acc: 0.7401     \n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4982 - acc: 0.7394     \n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4986 - acc: 0.7422     \n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4906 - acc: 0.7461     \n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4892 - acc: 0.7453     \n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4957 - acc: 0.7450     \n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4877 - acc: 0.7481     \n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4851 - acc: 0.7479     \n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4818 - acc: 0.7505     \n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4776 - acc: 0.7503     \n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4820 - acc: 0.7524     \n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4750 - acc: 0.7580     \n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4766 - acc: 0.7551     \n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4746 - acc: 0.7555     \n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4722 - acc: 0.7572     \n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4728 - acc: 0.7585     \n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4703 - acc: 0.7575     \n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4657 - acc: 0.7611     \n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4707 - acc: 0.7590     \n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4629 - acc: 0.7644     \n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4655 - acc: 0.7619     \n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4656 - acc: 0.7609     \n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4627 - acc: 0.7615     \n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4592 - acc: 0.7642     \n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4639 - acc: 0.7623     \n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4598 - acc: 0.7646     \n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4585 - acc: 0.7660     \n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4619 - acc: 0.7647     \n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.4545 - acc: 0.7669     \n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4563 - acc: 0.7668     \n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4574 - acc: 0.7661     \n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4511 - acc: 0.7688     \n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4548 - acc: 0.7685     \n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4505 - acc: 0.7705     \n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4496 - acc: 0.7695     \n",
      "Epoch 59/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4462 - acc: 0.7711     \n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4466 - acc: 0.7723     \n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4462 - acc: 0.7716     \n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4476 - acc: 0.7718     \n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4451 - acc: 0.7748     \n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4451 - acc: 0.7731     \n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4423 - acc: 0.7742     \n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4434 - acc: 0.7748     \n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4406 - acc: 0.7756     \n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4355 - acc: 0.7774     \n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4387 - acc: 0.7771     \n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4376 - acc: 0.7772     \n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4399 - acc: 0.7766     \n",
      "Epoch 72/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4364 - acc: 0.7790     \n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4358 - acc: 0.7794     \n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4358 - acc: 0.7814     \n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4317 - acc: 0.7832     \n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4326 - acc: 0.7800     \n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4335 - acc: 0.7794     \n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4335 - acc: 0.7814     \n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4308 - acc: 0.7820     \n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4313 - acc: 0.7823     \n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4317 - acc: 0.7833     \n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4283 - acc: 0.7842     \n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4269 - acc: 0.7841     \n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4280 - acc: 0.7824     \n",
      "Epoch 85/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4254 - acc: 0.7851     \n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4355 - acc: 0.7812     \n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4273 - acc: 0.7832     \n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4247 - acc: 0.7864     \n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4258 - acc: 0.7856     \n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4240 - acc: 0.7839     \n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4209 - acc: 0.7870     \n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4243 - acc: 0.7858     \n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4227 - acc: 0.7863     \n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4234 - acc: 0.7871     \n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4157 - acc: 0.7888     \n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4188 - acc: 0.7895     \n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4169 - acc: 0.7900     \n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4180 - acc: 0.7900     \n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4189 - acc: 0.7890     \n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4193 - acc: 0.7876     \n",
      "1632/2500 [==================>...........] - ETA: 0sEpoch 1/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6934 - acc: 0.5011     \n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6928 - acc: 0.5124     \n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6910 - acc: 0.5259     \n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6853 - acc: 0.5395     \n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6741 - acc: 0.5581     \n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6600 - acc: 0.5810     \n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6432 - acc: 0.5985     \n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6249 - acc: 0.6162     \n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6085 - acc: 0.6344     \n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5923 - acc: 0.6462     \n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5809 - acc: 0.6563     \n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5680 - acc: 0.6651     \n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5573 - acc: 0.6717     \n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5494 - acc: 0.6807     \n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5403 - acc: 0.6850     \n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5302 - acc: 0.6939     \n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5261 - acc: 0.6953     \n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5218 - acc: 0.7011     \n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5155 - acc: 0.7047     \n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5104 - acc: 0.7062     \n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5061 - acc: 0.7097     \n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5026 - acc: 0.7101     \n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4972 - acc: 0.7156     \n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4951 - acc: 0.7146     \n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4917 - acc: 0.7182     \n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4911 - acc: 0.7200     \n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4855 - acc: 0.7216     \n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4831 - acc: 0.7233     \n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4779 - acc: 0.7266     \n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4795 - acc: 0.7247     \n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4784 - acc: 0.7283     \n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4737 - acc: 0.7300     \n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4741 - acc: 0.7300     \n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4677 - acc: 0.7345     \n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4682 - acc: 0.7348     \n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 2s - loss: 0.4653 - acc: 0.7327     \n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4648 - acc: 0.7371     \n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4588 - acc: 0.7389     \n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4581 - acc: 0.7403     \n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4563 - acc: 0.7423     \n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4531 - acc: 0.7455     \n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4584 - acc: 0.7412     \n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4590 - acc: 0.7401     \n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4521 - acc: 0.7437     \n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4485 - acc: 0.7474     \n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4479 - acc: 0.7477     \n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4459 - acc: 0.7497     \n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4444 - acc: 0.7496     \n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4427 - acc: 0.7504     \n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4428 - acc: 0.7520     \n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4425 - acc: 0.7538     \n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4417 - acc: 0.7516     \n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4404 - acc: 0.7516     \n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4366 - acc: 0.7539     \n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4347 - acc: 0.7562     \n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4371 - acc: 0.7559     \n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4353 - acc: 0.7559     \n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4353 - acc: 0.7539     \n",
      "Epoch 59/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4322 - acc: 0.7557     \n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4311 - acc: 0.7604     \n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4316 - acc: 0.7575     \n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4259 - acc: 0.7599     \n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4271 - acc: 0.7580     \n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4294 - acc: 0.7587     \n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4252 - acc: 0.7608     \n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4257 - acc: 0.7607     \n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4259 - acc: 0.7597     \n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4257 - acc: 0.7608     \n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4206 - acc: 0.7629     \n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4200 - acc: 0.7624     \n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4207 - acc: 0.7628     \n",
      "Epoch 72/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4175 - acc: 0.7644     \n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4208 - acc: 0.7618     \n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4188 - acc: 0.7642     \n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4168 - acc: 0.7640     \n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4195 - acc: 0.7644     \n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4168 - acc: 0.7664     \n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4184 - acc: 0.7642     \n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4137 - acc: 0.7664     \n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4146 - acc: 0.7681     \n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4141 - acc: 0.7674     \n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4157 - acc: 0.7668     \n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4160 - acc: 0.7670     \n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4094 - acc: 0.7687     \n",
      "Epoch 85/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4105 - acc: 0.7672     \n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4146 - acc: 0.7646     \n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4120 - acc: 0.7668     \n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4068 - acc: 0.7682     \n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4077 - acc: 0.7688     \n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4100 - acc: 0.7664     \n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4078 - acc: 0.7686     \n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4045 - acc: 0.7707     \n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4040 - acc: 0.7713     \n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4052 - acc: 0.7696     \n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4047 - acc: 0.7724     \n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4003 - acc: 0.7723     \n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4037 - acc: 0.7714     \n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4064 - acc: 0.7699     \n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4010 - acc: 0.7723     \n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4016 - acc: 0.7724     \n",
      "1920/2500 [======================>.......] - ETA: 0sEpoch 1/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6933 - acc: 0.5063     \n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6922 - acc: 0.5188     \n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6885 - acc: 0.5365     \n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6799 - acc: 0.5543     \n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6650 - acc: 0.5817     \n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6468 - acc: 0.6017     \n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6265 - acc: 0.6172     \n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6094 - acc: 0.6320     \n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5965 - acc: 0.6422     \n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5837 - acc: 0.6540     \n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5754 - acc: 0.6593     \n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5656 - acc: 0.6683     \n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5565 - acc: 0.6736     \n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5499 - acc: 0.6788     \n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5415 - acc: 0.6845     \n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5370 - acc: 0.6842     \n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5329 - acc: 0.6919     \n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5266 - acc: 0.6941     \n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5261 - acc: 0.6969     \n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.5178 - acc: 0.7022     \n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5134 - acc: 0.7031     \n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5130 - acc: 0.7072     \n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5103 - acc: 0.7089     \n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5080 - acc: 0.7112     \n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5032 - acc: 0.7142     \n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5003 - acc: 0.7137     \n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4970 - acc: 0.7172     \n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4949 - acc: 0.7203     \n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4922 - acc: 0.7244     \n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4898 - acc: 0.7258     \n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4847 - acc: 0.7276     \n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4863 - acc: 0.7264     \n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4836 - acc: 0.7276     \n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4833 - acc: 0.7293     \n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4782 - acc: 0.7317     \n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4764 - acc: 0.7335     \n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4773 - acc: 0.7328     \n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4767 - acc: 0.7345     \n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4756 - acc: 0.7324     \n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4692 - acc: 0.7347     \n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4720 - acc: 0.7371     \n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4668 - acc: 0.7384     \n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4701 - acc: 0.7376     \n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4655 - acc: 0.7411     \n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4682 - acc: 0.7400     \n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4661 - acc: 0.7394     \n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4642 - acc: 0.7408     \n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4607 - acc: 0.7422     \n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4577 - acc: 0.7450     \n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4602 - acc: 0.7439     \n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4592 - acc: 0.7440     \n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4574 - acc: 0.7473     \n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4555 - acc: 0.7490     \n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4545 - acc: 0.7466     \n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4531 - acc: 0.7476     \n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4568 - acc: 0.7475     \n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4537 - acc: 0.7485     \n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4510 - acc: 0.7524     \n",
      "Epoch 59/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4468 - acc: 0.7552     \n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4487 - acc: 0.7539     \n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4470 - acc: 0.7519     \n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4401 - acc: 0.7564     \n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4431 - acc: 0.7565     \n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4452 - acc: 0.7568     \n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4468 - acc: 0.7597     \n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4404 - acc: 0.7596     \n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4442 - acc: 0.7584     \n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4394 - acc: 0.7579     \n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4369 - acc: 0.7609     \n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4385 - acc: 0.7608     \n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4423 - acc: 0.7607     \n",
      "Epoch 72/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4374 - acc: 0.7608     \n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4399 - acc: 0.7620     \n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4361 - acc: 0.7638     \n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4341 - acc: 0.7641     \n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4279 - acc: 0.7666     \n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4331 - acc: 0.7664     \n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4263 - acc: 0.7677     \n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4274 - acc: 0.7712     \n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4307 - acc: 0.7693     \n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4300 - acc: 0.7686     \n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4296 - acc: 0.7696     \n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4290 - acc: 0.7696     \n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4230 - acc: 0.7719     \n",
      "Epoch 85/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4303 - acc: 0.7684     \n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4319 - acc: 0.7693     \n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4229 - acc: 0.7737     \n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4230 - acc: 0.7743     \n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4274 - acc: 0.7730     \n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4280 - acc: 0.7712     \n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4197 - acc: 0.7750     \n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4254 - acc: 0.7732     \n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4222 - acc: 0.7743     \n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4180 - acc: 0.7765     \n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4244 - acc: 0.7733     \n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4231 - acc: 0.7749     \n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4216 - acc: 0.7732     \n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4185 - acc: 0.7786     \n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4212 - acc: 0.7763     \n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4190 - acc: 0.7782     \n",
      "1312/2500 [==============>...............] - ETA: 0sEpoch 1/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6931 - acc: 0.5030     \n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6921 - acc: 0.5137     \n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6897 - acc: 0.5323     \n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.6831 - acc: 0.5534     \n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6679 - acc: 0.5842     \n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6486 - acc: 0.6108     \n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6234 - acc: 0.6376     \n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6026 - acc: 0.6545     \n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5839 - acc: 0.6702     \n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5687 - acc: 0.6799     \n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5549 - acc: 0.6933     \n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5441 - acc: 0.7016     \n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5373 - acc: 0.7030     \n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5285 - acc: 0.7115     \n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5212 - acc: 0.7173     \n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5145 - acc: 0.7235     \n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5109 - acc: 0.7240     \n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5040 - acc: 0.7312     \n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5004 - acc: 0.7303     - ETA: 1s \n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4974 - acc: 0.7331     \n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4919 - acc: 0.7359     \n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4873 - acc: 0.7372     \n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4872 - acc: 0.7381     \n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4772 - acc: 0.7446     \n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4742 - acc: 0.7456     \n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4772 - acc: 0.7445     \n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4743 - acc: 0.7452     \n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4701 - acc: 0.7488     \n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4684 - acc: 0.7468     \n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4624 - acc: 0.7511     \n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4613 - acc: 0.7521     \n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4575 - acc: 0.7551     \n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4581 - acc: 0.7538     \n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4583 - acc: 0.7553     \n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4525 - acc: 0.7598     \n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4484 - acc: 0.7610     \n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4470 - acc: 0.7611     \n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4469 - acc: 0.7599     \n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4457 - acc: 0.7606     \n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4447 - acc: 0.7631     \n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4431 - acc: 0.7640     \n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4401 - acc: 0.7657     \n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4397 - acc: 0.7648     \n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4399 - acc: 0.7653     \n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4359 - acc: 0.7689     \n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4370 - acc: 0.7686     \n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4343 - acc: 0.7690     \n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4370 - acc: 0.7687     \n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4314 - acc: 0.7712     \n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4318 - acc: 0.7706     \n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4288 - acc: 0.7725     \n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4259 - acc: 0.7719     \n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4265 - acc: 0.7742     \n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4271 - acc: 0.7727     - ETA: 1s - \n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4251 - acc: 0.7735     \n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4276 - acc: 0.7736     \n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4249 - acc: 0.7730     \n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4246 - acc: 0.7742     \n",
      "Epoch 59/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4204 - acc: 0.7752     \n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4186 - acc: 0.7787     \n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4240 - acc: 0.7757     \n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4202 - acc: 0.7773     \n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4181 - acc: 0.7767     \n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4139 - acc: 0.7788     \n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4158 - acc: 0.7764     \n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4143 - acc: 0.7781     \n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4163 - acc: 0.7798     \n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4155 - acc: 0.7792     \n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4125 - acc: 0.7808     \n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4126 - acc: 0.7805     \n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4131 - acc: 0.7805     \n",
      "Epoch 72/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4116 - acc: 0.7816     \n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4070 - acc: 0.7827     \n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4106 - acc: 0.7827     \n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4073 - acc: 0.7826     \n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4091 - acc: 0.7824     \n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4069 - acc: 0.7862     \n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4088 - acc: 0.7823     \n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4051 - acc: 0.7864     \n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4048 - acc: 0.7853     \n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4031 - acc: 0.7867     \n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4045 - acc: 0.7848     \n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4026 - acc: 0.7868     \n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4007 - acc: 0.7869     \n",
      "Epoch 85/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4009 - acc: 0.7880     \n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3986 - acc: 0.7884     \n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3983 - acc: 0.7876     \n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.4005 - acc: 0.7874     \n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3960 - acc: 0.7904     \n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4017 - acc: 0.7884     \n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3966 - acc: 0.7900     \n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3966 - acc: 0.7899     \n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.3994 - acc: 0.7886     \n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3971 - acc: 0.7896     \n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3974 - acc: 0.7884     \n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3971 - acc: 0.7903     \n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3931 - acc: 0.7911     \n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3955 - acc: 0.7899     \n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3936 - acc: 0.7924     \n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3919 - acc: 0.7914     \n",
      "2208/2500 [=========================>....] - ETA: 0sEpoch 1/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6932 - acc: 0.4977     \n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5011     \n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6931 - acc: 0.5004     \n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6921 - acc: 0.5120     \n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6902 - acc: 0.5216     \n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6866 - acc: 0.5273     \n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6820 - acc: 0.5349     \n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6761 - acc: 0.5440     \n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6692 - acc: 0.5544     \n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6651 - acc: 0.5595     \n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6590 - acc: 0.5667     \n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6522 - acc: 0.5731     \n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6492 - acc: 0.5768     \n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6461 - acc: 0.5809     \n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6406 - acc: 0.5862     \n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6380 - acc: 0.5887     \n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6352 - acc: 0.5920     \n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6337 - acc: 0.5955     \n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6308 - acc: 0.5973     \n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6293 - acc: 0.5977     \n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6290 - acc: 0.5986     \n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6267 - acc: 0.6010     \n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6271 - acc: 0.6027     \n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6224 - acc: 0.6052     \n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6236 - acc: 0.6054     \n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6210 - acc: 0.6074     \n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6171 - acc: 0.6114     \n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6195 - acc: 0.6106     \n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6168 - acc: 0.6119     \n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6144 - acc: 0.6148     \n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6135 - acc: 0.6152     \n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6127 - acc: 0.6167     \n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6126 - acc: 0.6162     \n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6128 - acc: 0.6173     \n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6127 - acc: 0.6178     \n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6075 - acc: 0.6215     \n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6096 - acc: 0.6196     \n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6094 - acc: 0.6202     \n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6059 - acc: 0.6254     \n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6069 - acc: 0.6240     \n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6058 - acc: 0.6263     \n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6057 - acc: 0.6260     \n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6024 - acc: 0.6279     \n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6026 - acc: 0.6281     \n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6020 - acc: 0.6296     \n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5999 - acc: 0.6316     \n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5985 - acc: 0.6323     \n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5983 - acc: 0.6326     \n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5986 - acc: 0.6336     \n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5975 - acc: 0.6336     \n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5950 - acc: 0.6349     \n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5949 - acc: 0.6378     \n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5952 - acc: 0.6356     \n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5943 - acc: 0.6372     \n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5940 - acc: 0.6376     \n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5922 - acc: 0.6381     \n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5909 - acc: 0.6396     \n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5919 - acc: 0.6393     \n",
      "Epoch 59/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5910 - acc: 0.6396     \n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5906 - acc: 0.6406     \n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5881 - acc: 0.6425     \n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5886 - acc: 0.6415     \n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5902 - acc: 0.6437     \n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5854 - acc: 0.6461     \n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5867 - acc: 0.6450     \n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5885 - acc: 0.6454     \n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5872 - acc: 0.6458     \n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5847 - acc: 0.6470     \n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5840 - acc: 0.6475     \n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5830 - acc: 0.6490     \n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5841 - acc: 0.6484     \n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.5815 - acc: 0.6496     \n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5843 - acc: 0.6488     \n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5840 - acc: 0.6484     \n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5807 - acc: 0.6512     \n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5824 - acc: 0.6514     \n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5809 - acc: 0.6512     \n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5816 - acc: 0.6513     \n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5819 - acc: 0.6508     \n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5798 - acc: 0.6529     \n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5794 - acc: 0.6526     \n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5807 - acc: 0.6526     \n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5776 - acc: 0.6545     \n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5762 - acc: 0.6563     \n",
      "Epoch 85/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5755 - acc: 0.6565     \n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5766 - acc: 0.6559     \n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5776 - acc: 0.6558     \n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5751 - acc: 0.6557     \n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5738 - acc: 0.6586     \n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5767 - acc: 0.6573     \n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5749 - acc: 0.6582     \n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5718 - acc: 0.6596     \n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5734 - acc: 0.6592     \n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5727 - acc: 0.6607     \n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5715 - acc: 0.6608     \n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5702 - acc: 0.6629     \n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5711 - acc: 0.6610     \n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5734 - acc: 0.6608     \n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5713 - acc: 0.6622     \n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5709 - acc: 0.6625     \n",
      "1952/2500 [======================>.......] - ETA: 0sEpoch 1/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6934 - acc: 0.4972     \n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6928 - acc: 0.5100     \n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6901 - acc: 0.5309     \n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6843 - acc: 0.5481     \n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6740 - acc: 0.5752     \n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6572 - acc: 0.6002     \n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6385 - acc: 0.6194     \n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6185 - acc: 0.6471     \n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6003 - acc: 0.6626     \n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5865 - acc: 0.6757     \n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5742 - acc: 0.6877     \n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5626 - acc: 0.6930     \n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5536 - acc: 0.7049     \n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5436 - acc: 0.7116     \n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5366 - acc: 0.7185     \n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5303 - acc: 0.7211     \n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5227 - acc: 0.7253     \n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5190 - acc: 0.7270     \n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5132 - acc: 0.7323     \n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5109 - acc: 0.7347     \n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5063 - acc: 0.7358     \n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5014 - acc: 0.7411     \n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4970 - acc: 0.7437     \n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4971 - acc: 0.7428     \n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4908 - acc: 0.7498     \n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4908 - acc: 0.7498     \n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4836 - acc: 0.7543     \n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4817 - acc: 0.7527     \n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4804 - acc: 0.7550     \n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4759 - acc: 0.7574     \n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4777 - acc: 0.7576     \n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4735 - acc: 0.7587     \n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4730 - acc: 0.7613     \n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4694 - acc: 0.7609     \n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4669 - acc: 0.7640     \n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4638 - acc: 0.7660     \n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4644 - acc: 0.7663     \n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4604 - acc: 0.7675     \n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4560 - acc: 0.7697     \n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4534 - acc: 0.7727     \n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4577 - acc: 0.7696     \n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4523 - acc: 0.7721     \n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4498 - acc: 0.7729     \n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4570 - acc: 0.7725     \n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4477 - acc: 0.7775     \n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4461 - acc: 0.7747     \n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4437 - acc: 0.7774     \n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4443 - acc: 0.7774     \n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4437 - acc: 0.7767     \n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4437 - acc: 0.7761     \n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4382 - acc: 0.7784     \n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4383 - acc: 0.7795     \n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4414 - acc: 0.7808     \n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4382 - acc: 0.7821     \n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4372 - acc: 0.7821     \n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.4342 - acc: 0.7816     \n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4360 - acc: 0.7827     \n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4359 - acc: 0.7824     \n",
      "Epoch 59/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4362 - acc: 0.7822     \n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4294 - acc: 0.7847     \n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4284 - acc: 0.7866     \n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4315 - acc: 0.7836     \n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4282 - acc: 0.7876     \n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4299 - acc: 0.7877     \n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4251 - acc: 0.7877     \n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4295 - acc: 0.7842     \n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4294 - acc: 0.7855     \n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4267 - acc: 0.7872     \n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4239 - acc: 0.7890     \n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4218 - acc: 0.7900     \n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4238 - acc: 0.7884     \n",
      "Epoch 72/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4223 - acc: 0.7891     \n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4183 - acc: 0.7908     \n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4227 - acc: 0.7887     \n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4240 - acc: 0.7884     \n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4197 - acc: 0.7920     \n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4179 - acc: 0.7915     \n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4200 - acc: 0.7906     \n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4162 - acc: 0.7933     \n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4194 - acc: 0.7894     \n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4211 - acc: 0.7902     \n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4147 - acc: 0.7958     \n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4134 - acc: 0.7930     \n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4172 - acc: 0.7923     \n",
      "Epoch 85/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4112 - acc: 0.7930     \n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4159 - acc: 0.7931     \n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4138 - acc: 0.7941     \n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4091 - acc: 0.7962     \n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4120 - acc: 0.7929     \n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4128 - acc: 0.7948     \n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4106 - acc: 0.7971     \n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4111 - acc: 0.7947     \n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4130 - acc: 0.7944     \n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4105 - acc: 0.7955     \n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4075 - acc: 0.7969     \n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4130 - acc: 0.7957     \n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4080 - acc: 0.7971     \n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4031 - acc: 0.7975     \n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4051 - acc: 0.7981     \n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4060 - acc: 0.7968     \n",
      "2304/2500 [==========================>...] - ETA: 0sEpoch 1/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6932 - acc: 0.5020     \n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6921 - acc: 0.5177     \n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6891 - acc: 0.5334     \n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6816 - acc: 0.5551     \n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6695 - acc: 0.5780     \n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6524 - acc: 0.6056     \n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6304 - acc: 0.6329     \n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6108 - acc: 0.6535     \n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5957 - acc: 0.6708     \n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5803 - acc: 0.6851     \n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5683 - acc: 0.6952     \n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5576 - acc: 0.7049     \n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5489 - acc: 0.7113     \n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5421 - acc: 0.7180     \n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5359 - acc: 0.7225     \n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5284 - acc: 0.7276     \n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5239 - acc: 0.7303     \n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5200 - acc: 0.7348     \n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5149 - acc: 0.7373     \n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5103 - acc: 0.7406     \n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5101 - acc: 0.7434     \n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5039 - acc: 0.7473     \n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5020 - acc: 0.7477     \n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4975 - acc: 0.7495     \n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4950 - acc: 0.7547     \n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4908 - acc: 0.7567     \n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4910 - acc: 0.7552     \n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4883 - acc: 0.7576     \n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4883 - acc: 0.7592     \n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4844 - acc: 0.7621     \n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4793 - acc: 0.7618     \n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4793 - acc: 0.7646     \n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4765 - acc: 0.7645     \n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4757 - acc: 0.7673     \n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4736 - acc: 0.7675     \n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4723 - acc: 0.7688     \n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4722 - acc: 0.7677     \n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4722 - acc: 0.7705     \n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4675 - acc: 0.7720     \n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.4651 - acc: 0.7739     \n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4644 - acc: 0.7741     \n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4591 - acc: 0.7794     \n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4595 - acc: 0.7756     \n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4597 - acc: 0.7777     \n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4626 - acc: 0.7752     \n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4588 - acc: 0.7792     \n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4576 - acc: 0.7791     \n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4533 - acc: 0.7811     \n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4533 - acc: 0.7839     \n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4527 - acc: 0.7833     \n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4540 - acc: 0.7805     \n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4536 - acc: 0.7839     \n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4545 - acc: 0.7829     \n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4469 - acc: 0.7874     \n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4484 - acc: 0.7859     \n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4491 - acc: 0.7841     \n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4458 - acc: 0.7850     \n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4439 - acc: 0.7903     \n",
      "Epoch 59/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4451 - acc: 0.7880     \n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4417 - acc: 0.7900     \n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4448 - acc: 0.7880     \n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4408 - acc: 0.7900     \n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4403 - acc: 0.7896     \n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4383 - acc: 0.7911     \n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4396 - acc: 0.7906     \n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4397 - acc: 0.7918     \n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4384 - acc: 0.7905     \n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4343 - acc: 0.7946     \n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4380 - acc: 0.7932     \n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4336 - acc: 0.7955     \n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4312 - acc: 0.7969     \n",
      "Epoch 72/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4307 - acc: 0.7974     \n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4316 - acc: 0.7962     \n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4291 - acc: 0.7970     \n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4331 - acc: 0.7947     \n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4304 - acc: 0.7982     \n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4299 - acc: 0.7980     \n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4258 - acc: 0.8002     \n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4237 - acc: 0.8024     \n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4241 - acc: 0.8014     \n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4269 - acc: 0.8011     \n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4300 - acc: 0.7981     \n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4235 - acc: 0.8018     \n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4248 - acc: 0.8007     \n",
      "Epoch 85/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4255 - acc: 0.8005     \n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4237 - acc: 0.8012     \n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4247 - acc: 0.8004     \n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4235 - acc: 0.8006     \n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4231 - acc: 0.7997     \n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4177 - acc: 0.8040     \n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4199 - acc: 0.8010     \n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4222 - acc: 0.8019     \n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4212 - acc: 0.8007     \n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4186 - acc: 0.8059     \n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4166 - acc: 0.8068     \n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4192 - acc: 0.8029     \n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4169 - acc: 0.8054     \n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4143 - acc: 0.8066     \n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4148 - acc: 0.8068     \n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.4160 - acc: 0.8054     \n",
      "1792/2500 [====================>.........] - ETA: 0sEpoch 1/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6933 - acc: 0.5003     \n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5037     \n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6928 - acc: 0.5085     \n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6912 - acc: 0.5222     \n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6884 - acc: 0.5339     \n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6827 - acc: 0.5455     \n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6739 - acc: 0.5598     \n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6649 - acc: 0.5684     \n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6555 - acc: 0.5802     \n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6460 - acc: 0.5882     \n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6378 - acc: 0.5962     \n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6298 - acc: 0.6039     \n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6248 - acc: 0.6075     \n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6191 - acc: 0.6116     \n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6137 - acc: 0.6180     \n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6139 - acc: 0.6192     \n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6066 - acc: 0.6215     \n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6027 - acc: 0.6239     \n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5994 - acc: 0.6284     \n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5967 - acc: 0.6311     \n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5944 - acc: 0.6320     \n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5915 - acc: 0.6352     \n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5871 - acc: 0.6362     \n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.5889 - acc: 0.6347     \n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5863 - acc: 0.6372     \n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5833 - acc: 0.6401     \n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5789 - acc: 0.6433     \n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5791 - acc: 0.6429     \n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5745 - acc: 0.6472     \n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5766 - acc: 0.6471     \n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5713 - acc: 0.6489     \n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5723 - acc: 0.6480     \n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5715 - acc: 0.6489     \n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5684 - acc: 0.6523     \n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5641 - acc: 0.6539     \n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5662 - acc: 0.6544     \n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5625 - acc: 0.6565     \n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5623 - acc: 0.6555     \n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5620 - acc: 0.6570     \n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5606 - acc: 0.6570     \n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5603 - acc: 0.6577     \n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5612 - acc: 0.6594     \n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5579 - acc: 0.6596     \n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5573 - acc: 0.6606     \n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5570 - acc: 0.6621     \n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5561 - acc: 0.6610     \n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5565 - acc: 0.6623     \n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5528 - acc: 0.6636     \n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5523 - acc: 0.6644     \n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5493 - acc: 0.6670     \n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5492 - acc: 0.6663     \n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5472 - acc: 0.6682     \n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5431 - acc: 0.6696     \n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5458 - acc: 0.6683     \n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5453 - acc: 0.6686     \n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5472 - acc: 0.6672     \n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5460 - acc: 0.6689     \n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5446 - acc: 0.6694     \n",
      "Epoch 59/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5423 - acc: 0.6711     \n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5402 - acc: 0.6740     \n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5419 - acc: 0.6727     \n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5382 - acc: 0.6747     \n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5409 - acc: 0.6714     \n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5421 - acc: 0.6718     \n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5388 - acc: 0.6741     \n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5374 - acc: 0.6743     \n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5335 - acc: 0.6761     \n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5362 - acc: 0.6757     \n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5350 - acc: 0.6765     \n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5353 - acc: 0.6765     \n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5341 - acc: 0.6766     \n",
      "Epoch 72/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5340 - acc: 0.6769     \n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5319 - acc: 0.6774     \n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5333 - acc: 0.6785     \n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5326 - acc: 0.6786     \n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5320 - acc: 0.6785     \n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5292 - acc: 0.6802     \n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5288 - acc: 0.6803     \n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5300 - acc: 0.6799     \n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5295 - acc: 0.6807     \n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5303 - acc: 0.6798     \n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5280 - acc: 0.6824     \n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5263 - acc: 0.6833     \n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5267 - acc: 0.6824     \n",
      "Epoch 85/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5257 - acc: 0.6831     \n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5252 - acc: 0.6827     \n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5252 - acc: 0.6837     \n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5272 - acc: 0.6828     \n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5257 - acc: 0.6827     \n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5216 - acc: 0.6860     \n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5223 - acc: 0.6837     \n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5223 - acc: 0.6840     \n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5218 - acc: 0.6856     \n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5210 - acc: 0.6860     \n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5224 - acc: 0.6843     \n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5191 - acc: 0.6856     \n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.5216 - acc: 0.6858     \n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5238 - acc: 0.6856     \n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5166 - acc: 0.6887     \n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5224 - acc: 0.6865     \n",
      "1600/2500 [==================>...........] - ETA: 0s Accuracy mean: 0.50228\n",
      "Accuracy variance: 0.00512265556133\n"
     ]
    }
   ],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 100)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 50.696000 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 53.404000 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 51.652000 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 54.508000 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 50.416000 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
