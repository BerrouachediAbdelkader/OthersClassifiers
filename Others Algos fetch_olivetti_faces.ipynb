{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GcForeest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/olivetti.json\") \n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-21 22:17:51,163][cascade_classifier.fit_transform] X_groups_train.shape=[(25000, 500)],y_train.shape=(25000,),X_groups_test.shape=[(25000, 500)],y_test.shape=(25000,)\n",
      "[ 2018-04-21 22:17:51,225][cascade_classifier.fit_transform] group_dims=[500]\n",
      "[ 2018-04-21 22:17:51,227][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-04-21 22:17:51,229][cascade_classifier.fit_transform] group_ends=[500]\n",
      "[ 2018-04-21 22:17:51,230][cascade_classifier.fit_transform] X_train.shape=(25000, 500),X_test.shape=(25000, 500)\n",
      "[ 2018-04-21 22:17:51,305][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(25000, 500), X_cur_test.shape=(25000, 500)\n",
      "[ 2018-04-21 22:17:52,773][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=54.52%\n",
      "[ 2018-04-21 22:17:54,347][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=53.08%\n",
      "[ 2018-04-21 22:17:55,914][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=53.12%\n",
      "[ 2018-04-21 22:17:57,460][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=55.08%\n",
      "[ 2018-04-21 22:17:59,025][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=53.40%\n",
      "[ 2018-04-21 22:18:00,572][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=54.96%\n",
      "[ 2018-04-21 22:18:02,193][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=55.40%\n",
      "[ 2018-04-21 22:18:03,879][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=54.60%\n",
      "[ 2018-04-21 22:18:05,427][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=53.28%\n",
      "[ 2018-04-21 22:18:07,019][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=55.28%\n",
      "[ 2018-04-21 22:18:07,187][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=54.27%\n",
      "[ 2018-04-21 22:18:07,190][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=55.00%\n",
      "[ 2018-04-21 22:18:08,624][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=52.20%\n",
      "[ 2018-04-21 22:18:10,284][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=51.60%\n",
      "[ 2018-04-21 22:18:11,928][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=51.52%\n",
      "[ 2018-04-21 22:18:13,469][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=53.28%\n",
      "[ 2018-04-21 22:18:15,040][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=53.28%\n",
      "[ 2018-04-21 22:18:16,549][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=50.80%\n",
      "[ 2018-04-21 22:18:18,227][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=51.36%\n",
      "[ 2018-04-21 22:18:19,756][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=52.72%\n",
      "[ 2018-04-21 22:18:21,318][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=52.56%\n",
      "[ 2018-04-21 22:18:22,860][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=52.80%\n",
      "[ 2018-04-21 22:18:23,031][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=52.21%\n",
      "[ 2018-04-21 22:18:23,033][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=52.94%\n",
      "[ 2018-04-21 22:18:43,877][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=49.48%\n",
      "[ 2018-04-21 22:19:04,603][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=50.28%\n",
      "[ 2018-04-21 22:19:22,939][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=52.04%\n",
      "[ 2018-04-21 22:19:40,372][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=51.44%\n",
      "[ 2018-04-21 22:20:00,457][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=52.04%\n",
      "[ 2018-04-21 22:20:20,983][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=50.80%\n",
      "[ 2018-04-21 22:20:42,636][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=49.56%\n",
      "[ 2018-04-21 22:21:06,298][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=51.32%\n",
      "[ 2018-04-21 22:21:30,044][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=50.68%\n",
      "[ 2018-04-21 22:21:49,858][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=52.16%\n",
      "[ 2018-04-21 22:21:49,875][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=50.98%\n",
      "[ 2018-04-21 22:21:49,878][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=50.91%\n",
      "[ 2018-04-21 22:21:49,881][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=53.05%\n",
      "[ 2018-04-21 22:21:49,883][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=53.13%\n",
      "[ 2018-04-21 22:21:49,965][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(25000, 506), X_cur_test.shape=(25000, 506)\n",
      "[ 2018-04-21 22:21:51,432][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=56.12%\n",
      "[ 2018-04-21 22:21:52,864][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=50.88%\n",
      "[ 2018-04-21 22:21:54,495][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=51.68%\n",
      "[ 2018-04-21 22:21:56,156][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=50.84%\n",
      "[ 2018-04-21 22:21:57,685][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=51.80%\n",
      "[ 2018-04-21 22:21:59,265][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=53.20%\n",
      "[ 2018-04-21 22:22:00,813][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=53.28%\n",
      "[ 2018-04-21 22:22:02,355][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=55.24%\n",
      "[ 2018-04-21 22:22:03,936][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=54.96%\n",
      "[ 2018-04-21 22:22:05,496][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=53.64%\n",
      "[ 2018-04-21 22:22:05,679][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=53.16%\n",
      "[ 2018-04-21 22:22:05,682][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=54.96%\n",
      "[ 2018-04-21 22:22:07,080][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=51.84%\n",
      "[ 2018-04-21 22:22:08,709][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=52.48%\n",
      "[ 2018-04-21 22:22:10,420][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=53.16%\n",
      "[ 2018-04-21 22:22:12,080][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=52.64%\n",
      "[ 2018-04-21 22:22:13,716][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=51.16%\n",
      "[ 2018-04-21 22:22:15,248][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=54.64%\n",
      "[ 2018-04-21 22:22:16,820][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=51.48%\n",
      "[ 2018-04-21 22:22:18,517][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=54.24%\n",
      "[ 2018-04-21 22:22:20,163][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=52.48%\n",
      "[ 2018-04-21 22:22:22,060][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=51.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-21 22:22:22,376][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=52.52%\n",
      "[ 2018-04-21 22:22:22,379][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=53.45%\n",
      "[ 2018-04-21 22:22:55,622][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=59.52%\n",
      "[ 2018-04-21 22:23:28,469][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=56.40%\n",
      "[ 2018-04-21 22:24:00,737][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=55.40%\n",
      "[ 2018-04-21 22:24:33,137][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=55.52%\n",
      "[ 2018-04-21 22:25:05,594][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=56.52%\n",
      "[ 2018-04-21 22:25:37,178][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=55.32%\n",
      "[ 2018-04-21 22:26:08,678][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=54.68%\n",
      "[ 2018-04-21 22:26:41,046][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=53.52%\n",
      "[ 2018-04-21 22:27:13,520][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=56.44%\n",
      "[ 2018-04-21 22:27:45,467][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=57.36%\n",
      "[ 2018-04-21 22:27:45,489][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=56.07%\n",
      "[ 2018-04-21 22:27:45,491][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=52.47%\n",
      "[ 2018-04-21 22:27:45,494][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=55.80%\n",
      "[ 2018-04-21 22:27:45,496][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=53.79%\n",
      "[ 2018-04-21 22:27:45,593][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(25000, 506), X_cur_test.shape=(25000, 506)\n",
      "[ 2018-04-21 22:27:46,970][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=54.28%\n",
      "[ 2018-04-21 22:27:48,519][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=55.40%\n",
      "[ 2018-04-21 22:27:50,120][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=54.32%\n",
      "[ 2018-04-21 22:27:51,700][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=55.20%\n",
      "[ 2018-04-21 22:27:53,265][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=54.44%\n",
      "[ 2018-04-21 22:27:54,828][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=54.92%\n",
      "[ 2018-04-21 22:27:56,386][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=55.48%\n",
      "[ 2018-04-21 22:27:58,087][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=55.44%\n",
      "[ 2018-04-21 22:27:59,649][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=54.40%\n",
      "[ 2018-04-21 22:28:01,208][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=58.40%\n",
      "[ 2018-04-21 22:28:01,384][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=55.23%\n",
      "[ 2018-04-21 22:28:01,387][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=54.22%\n",
      "[ 2018-04-21 22:28:02,792][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=53.52%\n",
      "[ 2018-04-21 22:28:04,448][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=53.08%\n",
      "[ 2018-04-21 22:28:06,027][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=53.48%\n",
      "[ 2018-04-21 22:28:08,645][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=54.40%\n",
      "[ 2018-04-21 22:28:10,316][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=52.28%\n",
      "[ 2018-04-21 22:28:12,137][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=55.00%\n",
      "[ 2018-04-21 22:28:13,669][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=54.60%\n",
      "[ 2018-04-21 22:28:15,207][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=55.36%\n",
      "[ 2018-04-21 22:28:17,531][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=52.84%\n",
      "[ 2018-04-21 22:28:19,268][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=53.00%\n",
      "[ 2018-04-21 22:28:19,435][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=53.76%\n",
      "[ 2018-04-21 22:28:19,437][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=52.82%\n",
      "[ 2018-04-21 22:28:48,740][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=51.72%\n",
      "[ 2018-04-21 22:29:18,914][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=52.56%\n",
      "[ 2018-04-21 22:29:46,742][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=51.44%\n",
      "[ 2018-04-21 22:30:15,621][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=53.12%\n",
      "[ 2018-04-21 22:30:49,293][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=52.84%\n",
      "[ 2018-04-21 22:31:20,083][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=52.28%\n",
      "[ 2018-04-21 22:31:52,432][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=52.92%\n",
      "[ 2018-04-21 22:32:25,325][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=52.24%\n",
      "[ 2018-04-21 22:32:55,038][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=51.64%\n",
      "[ 2018-04-21 22:33:23,288][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=51.04%\n",
      "[ 2018-04-21 22:33:23,309][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=52.18%\n",
      "[ 2018-04-21 22:33:23,311][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=52.95%\n",
      "[ 2018-04-21 22:33:23,315][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=54.48%\n",
      "[ 2018-04-21 22:33:23,317][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=53.31%\n",
      "[ 2018-04-21 22:33:23,403][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(25000, 506), X_cur_test.shape=(25000, 506)\n",
      "[ 2018-04-21 22:33:24,851][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=54.56%\n",
      "[ 2018-04-21 22:33:26,400][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=55.52%\n",
      "[ 2018-04-21 22:33:27,880][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=53.28%\n",
      "[ 2018-04-21 22:33:29,428][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=53.28%\n",
      "[ 2018-04-21 22:33:30,978][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=56.24%\n",
      "[ 2018-04-21 22:33:32,496][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=54.64%\n",
      "[ 2018-04-21 22:33:34,085][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=54.52%\n",
      "[ 2018-04-21 22:33:35,622][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=53.72%\n",
      "[ 2018-04-21 22:33:37,210][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=55.08%\n",
      "[ 2018-04-21 22:33:38,912][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=54.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-21 22:33:39,098][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=54.52%\n",
      "[ 2018-04-21 22:33:39,100][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=54.74%\n",
      "[ 2018-04-21 22:33:40,576][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=53.84%\n",
      "[ 2018-04-21 22:33:42,288][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=52.96%\n",
      "[ 2018-04-21 22:33:43,918][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=53.52%\n",
      "[ 2018-04-21 22:33:45,458][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=53.40%\n",
      "[ 2018-04-21 22:33:47,003][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=51.48%\n",
      "[ 2018-04-21 22:33:48,642][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=51.52%\n",
      "[ 2018-04-21 22:33:50,186][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=53.80%\n",
      "[ 2018-04-21 22:33:51,752][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=53.00%\n",
      "[ 2018-04-21 22:33:53,347][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=53.68%\n",
      "[ 2018-04-21 22:33:55,046][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=54.20%\n",
      "[ 2018-04-21 22:33:55,353][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=53.14%\n",
      "[ 2018-04-21 22:33:55,356][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=53.27%\n",
      "[ 2018-04-21 22:34:28,930][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=53.92%\n",
      "[ 2018-04-21 22:35:00,934][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=54.48%\n",
      "[ 2018-04-21 22:35:33,571][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=54.84%\n",
      "[ 2018-04-21 22:36:06,417][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=53.80%\n",
      "[ 2018-04-21 22:36:38,701][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=56.60%\n",
      "[ 2018-04-21 22:37:10,762][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=54.88%\n",
      "[ 2018-04-21 22:37:43,556][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=55.48%\n",
      "[ 2018-04-21 22:38:15,938][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=54.72%\n",
      "[ 2018-04-21 22:38:48,362][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=54.68%\n",
      "[ 2018-04-21 22:39:21,113][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=56.92%\n",
      "[ 2018-04-21 22:39:21,133][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=55.03%\n",
      "[ 2018-04-21 22:39:21,136][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=51.92%\n",
      "[ 2018-04-21 22:39:21,139][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=55.88%\n",
      "[ 2018-04-21 22:39:21,141][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=53.42%\n",
      "[ 2018-04-21 22:39:21,223][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(25000, 506), X_cur_test.shape=(25000, 506)\n",
      "[ 2018-04-21 22:39:22,595][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_0.predict)=54.16%\n",
      "[ 2018-04-21 22:39:24,005][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_1.predict)=55.08%\n",
      "[ 2018-04-21 22:39:25,580][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_2.predict)=53.56%\n",
      "[ 2018-04-21 22:39:27,270][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_3.predict)=53.56%\n",
      "[ 2018-04-21 22:39:28,966][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_4.predict)=56.00%\n",
      "[ 2018-04-21 22:39:30,597][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_5.predict)=53.40%\n",
      "[ 2018-04-21 22:39:32,190][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_6.predict)=54.40%\n",
      "[ 2018-04-21 22:39:33,748][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_7.predict)=55.56%\n",
      "[ 2018-04-21 22:39:35,319][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_8.predict)=54.60%\n",
      "[ 2018-04-21 22:39:37,033][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_9.predict)=55.04%\n",
      "[ 2018-04-21 22:39:37,329][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_cv.predict)=54.54%\n",
      "[ 2018-04-21 22:39:37,332][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.test.predict)=54.28%\n",
      "[ 2018-04-21 22:39:38,815][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_0.predict)=53.48%\n",
      "[ 2018-04-21 22:39:40,376][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_1.predict)=52.56%\n",
      "[ 2018-04-21 22:39:42,092][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_2.predict)=52.80%\n",
      "[ 2018-04-21 22:39:43,618][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_3.predict)=54.36%\n",
      "[ 2018-04-21 22:39:45,275][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_4.predict)=53.96%\n",
      "[ 2018-04-21 22:39:46,837][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_5.predict)=53.16%\n",
      "[ 2018-04-21 22:39:48,471][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_6.predict)=53.40%\n",
      "[ 2018-04-21 22:39:50,114][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_7.predict)=53.64%\n",
      "[ 2018-04-21 22:39:51,820][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_8.predict)=54.80%\n",
      "[ 2018-04-21 22:39:53,506][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_9.predict)=53.40%\n",
      "[ 2018-04-21 22:39:53,679][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_cv.predict)=53.56%\n",
      "[ 2018-04-21 22:39:53,681][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.test.predict)=53.02%\n",
      "[ 2018-04-21 22:40:23,925][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_0.predict)=52.84%\n",
      "[ 2018-04-21 22:40:55,769][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_1.predict)=53.68%\n",
      "[ 2018-04-21 22:41:24,667][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_2.predict)=54.32%\n",
      "[ 2018-04-21 22:41:50,538][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_3.predict)=50.60%\n",
      "[ 2018-04-21 22:42:16,302][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_4.predict)=54.84%\n",
      "[ 2018-04-21 22:42:47,123][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_5.predict)=51.76%\n",
      "[ 2018-04-21 22:43:17,200][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_6.predict)=50.84%\n",
      "[ 2018-04-21 22:43:47,674][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_7.predict)=51.24%\n",
      "[ 2018-04-21 22:44:14,920][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_8.predict)=51.96%\n",
      "[ 2018-04-21 22:44:43,791][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_9.predict)=53.20%\n",
      "[ 2018-04-21 22:44:43,811][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_cv.predict)=52.53%\n",
      "[ 2018-04-21 22:44:43,813][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.test.predict)=52.86%\n",
      "[ 2018-04-21 22:44:43,817][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=54.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-21 22:44:43,819][cascade_classifier.calc_accuracy] Accuracy(layer_4 - test.classifier_average)=53.56%\n",
      "[ 2018-04-21 22:44:43,900][cascade_classifier.fit_transform] [layer=5] look_indexs=[0], X_cur_train.shape=(25000, 506), X_cur_test.shape=(25000, 506)\n",
      "[ 2018-04-21 22:44:45,305][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_0.predict)=53.88%\n",
      "[ 2018-04-21 22:44:46,887][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_1.predict)=52.20%\n",
      "[ 2018-04-21 22:44:48,445][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_2.predict)=53.56%\n",
      "[ 2018-04-21 22:44:50,076][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_3.predict)=55.52%\n",
      "[ 2018-04-21 22:44:51,775][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_4.predict)=53.00%\n",
      "[ 2018-04-21 22:44:53,465][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_5.predict)=52.88%\n",
      "[ 2018-04-21 22:44:55,049][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_6.predict)=54.12%\n",
      "[ 2018-04-21 22:44:56,773][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_7.predict)=55.44%\n",
      "[ 2018-04-21 22:44:58,367][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_8.predict)=54.72%\n",
      "[ 2018-04-21 22:45:00,077][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_9.predict)=54.76%\n",
      "[ 2018-04-21 22:45:00,272][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_cv.predict)=54.01%\n",
      "[ 2018-04-21 22:45:00,275][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.test.predict)=54.76%\n",
      "[ 2018-04-21 22:45:01,696][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_0.predict)=53.80%\n",
      "[ 2018-04-21 22:45:03,249][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_1.predict)=52.96%\n",
      "[ 2018-04-21 22:45:05,253][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_2.predict)=52.36%\n",
      "[ 2018-04-21 22:45:07,007][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_3.predict)=53.88%\n",
      "[ 2018-04-21 22:45:08,671][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_4.predict)=52.96%\n",
      "[ 2018-04-21 22:45:10,657][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_5.predict)=51.48%\n",
      "[ 2018-04-21 22:45:12,334][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_6.predict)=53.72%\n",
      "[ 2018-04-21 22:45:14,002][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_7.predict)=52.40%\n",
      "[ 2018-04-21 22:45:15,549][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_8.predict)=52.24%\n",
      "[ 2018-04-21 22:45:17,093][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_9.predict)=52.68%\n",
      "[ 2018-04-21 22:45:17,393][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_cv.predict)=52.85%\n",
      "[ 2018-04-21 22:45:17,396][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.test.predict)=53.07%\n",
      "[ 2018-04-21 22:45:51,377][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_0.predict)=55.00%\n",
      "[ 2018-04-21 22:46:30,963][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_1.predict)=53.40%\n",
      "[ 2018-04-21 22:47:05,056][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_2.predict)=54.04%\n",
      "[ 2018-04-21 22:47:38,700][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_3.predict)=53.16%\n",
      "[ 2018-04-21 22:48:12,684][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_4.predict)=55.32%\n",
      "[ 2018-04-21 22:48:48,312][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_5.predict)=54.92%\n",
      "[ 2018-04-21 22:49:23,897][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_6.predict)=54.20%\n",
      "[ 2018-04-21 22:49:59,394][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_7.predict)=54.92%\n",
      "[ 2018-04-21 22:50:33,426][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_8.predict)=53.16%\n",
      "[ 2018-04-21 22:51:06,982][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_9.predict)=53.64%\n",
      "[ 2018-04-21 22:51:07,002][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_cv.predict)=54.18%\n",
      "[ 2018-04-21 22:51:07,004][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.test.predict)=51.66%\n",
      "[ 2018-04-21 22:51:07,007][cascade_classifier.calc_accuracy] Accuracy(layer_5 - train.classifier_average)=54.84%\n",
      "[ 2018-04-21 22:51:07,009][cascade_classifier.calc_accuracy] Accuracy(layer_5 - test.classifier_average)=53.45%\n",
      "[ 2018-04-21 22:51:07,090][cascade_classifier.fit_transform] [layer=6] look_indexs=[0], X_cur_train.shape=(25000, 506), X_cur_test.shape=(25000, 506)\n",
      "[ 2018-04-21 22:51:08,498][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_0.predict)=54.76%\n",
      "[ 2018-04-21 22:51:09,962][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_1.predict)=53.24%\n",
      "[ 2018-04-21 22:51:11,387][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_2.predict)=54.24%\n",
      "[ 2018-04-21 22:51:12,840][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_3.predict)=54.92%\n",
      "[ 2018-04-21 22:51:14,412][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_4.predict)=55.52%\n",
      "[ 2018-04-21 22:51:15,993][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_5.predict)=52.72%\n",
      "[ 2018-04-21 22:51:17,440][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_6.predict)=54.36%\n",
      "[ 2018-04-21 22:51:18,877][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_7.predict)=54.76%\n",
      "[ 2018-04-21 22:51:20,360][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_8.predict)=54.96%\n",
      "[ 2018-04-21 22:51:21,847][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_9.predict)=53.00%\n",
      "[ 2018-04-21 22:51:22,027][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_cv.predict)=54.25%\n",
      "[ 2018-04-21 22:51:22,030][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.test.predict)=54.48%\n",
      "[ 2018-04-21 22:51:23,306][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_0.predict)=51.52%\n",
      "[ 2018-04-21 22:51:24,613][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_1.predict)=53.52%\n",
      "[ 2018-04-21 22:51:25,892][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_2.predict)=53.96%\n",
      "[ 2018-04-21 22:51:27,387][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_3.predict)=52.20%\n",
      "[ 2018-04-21 22:51:28,731][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_4.predict)=52.04%\n",
      "[ 2018-04-21 22:51:29,909][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_5.predict)=53.04%\n",
      "[ 2018-04-21 22:51:31,455][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_6.predict)=54.56%\n",
      "[ 2018-04-21 22:51:32,942][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_7.predict)=52.28%\n",
      "[ 2018-04-21 22:51:34,293][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_8.predict)=54.96%\n",
      "[ 2018-04-21 22:51:35,658][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_9.predict)=53.12%\n",
      "[ 2018-04-21 22:51:35,843][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_cv.predict)=53.12%\n",
      "[ 2018-04-21 22:51:35,845][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.test.predict)=53.37%\n",
      "[ 2018-04-21 22:52:07,409][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_0.predict)=50.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-21 22:52:37,371][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_1.predict)=52.16%\n",
      "[ 2018-04-21 22:53:04,971][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_2.predict)=52.52%\n",
      "[ 2018-04-21 22:53:35,728][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_3.predict)=53.00%\n",
      "[ 2018-04-21 22:54:02,296][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_4.predict)=51.88%\n",
      "[ 2018-04-21 22:54:27,031][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_5.predict)=51.24%\n",
      "[ 2018-04-21 22:54:54,137][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_6.predict)=51.76%\n",
      "[ 2018-04-21 22:55:23,334][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_7.predict)=53.52%\n",
      "[ 2018-04-21 22:55:54,584][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_8.predict)=53.96%\n",
      "[ 2018-04-21 22:56:21,981][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_9.predict)=53.00%\n",
      "[ 2018-04-21 22:56:21,999][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_cv.predict)=52.32%\n",
      "[ 2018-04-21 22:56:22,002][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.test.predict)=52.44%\n",
      "[ 2018-04-21 22:56:22,005][cascade_classifier.calc_accuracy] Accuracy(layer_6 - train.classifier_average)=53.74%\n",
      "[ 2018-04-21 22:56:22,006][cascade_classifier.calc_accuracy] Accuracy(layer_6 - test.classifier_average)=53.41%\n",
      "[ 2018-04-21 22:56:22,008][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=4, accuracy_train=55.88%, accuracy_test=53.42%\n"
     ]
    }
   ],
   "source": [
    "    # X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-21 22:56:22,277][cascade_classifier.transform] X_groups_test.shape=[(25000, 500)]\n",
      "[ 2018-04-21 22:56:22,298][cascade_classifier.transform] group_dims=[500]\n",
      "[ 2018-04-21 22:56:22,300][cascade_classifier.transform] X_test.shape=(25000, 500)\n",
      "[ 2018-04-21 22:56:22,334][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(25000, 500)\n",
      "[ 2018-04-21 22:56:38,833][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(25000, 506)\n",
      "[ 2018-04-21 22:56:51,238][cascade_classifier.transform] [layer=2] look_indexs=[0], X_cur_test.shape=(25000, 506)\n",
      "[ 2018-04-21 22:57:03,091][cascade_classifier.transform] [layer=3] look_indexs=[0], X_cur_test.shape=(25000, 506)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 53.420000 %\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6930 - acc: 0.5056     \n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6900 - acc: 0.5356     \n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6843 - acc: 0.5560     \n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6716 - acc: 0.5802     \n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6522 - acc: 0.6026     \n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6283 - acc: 0.6260     \n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6058 - acc: 0.6503     \n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5871 - acc: 0.6664     \n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5702 - acc: 0.6776     \n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5565 - acc: 0.6910     \n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5465 - acc: 0.6967     \n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5360 - acc: 0.7042     \n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5280 - acc: 0.7079     \n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5193 - acc: 0.7144     \n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5127 - acc: 0.7215     \n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - ETA: 0s - loss: 0.5057 - acc: 0.724 - 1s - loss: 0.5070 - acc: 0.7232     \n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5005 - acc: 0.7269     \n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4964 - acc: 0.7289     \n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4932 - acc: 0.7334     \n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4888 - acc: 0.7332     \n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4854 - acc: 0.7356     \n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4831 - acc: 0.7379     \n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4776 - acc: 0.7418     \n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4764 - acc: 0.7443     \n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4682 - acc: 0.7455     \n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4695 - acc: 0.7458     \n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4688 - acc: 0.7463     \n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4637 - acc: 0.7516     \n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4616 - acc: 0.7520     \n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4569 - acc: 0.7526     \n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4545 - acc: 0.7558     \n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4565 - acc: 0.7559     \n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4514 - acc: 0.7597     \n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4508 - acc: 0.7569     \n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4464 - acc: 0.7610     \n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4442 - acc: 0.7604     \n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4475 - acc: 0.7612     \n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4442 - acc: 0.7640     \n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4399 - acc: 0.7641     \n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4398 - acc: 0.7644     \n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4386 - acc: 0.7648     \n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4361 - acc: 0.7668     \n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4331 - acc: 0.7689     \n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4333 - acc: 0.7664     \n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4336 - acc: 0.7693     \n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4288 - acc: 0.7699     \n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4290 - acc: 0.7718     \n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4292 - acc: 0.7705     \n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4260 - acc: 0.7739     \n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4257 - acc: 0.7717     \n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4240 - acc: 0.7748     \n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4273 - acc: 0.7725     \n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4247 - acc: 0.7752     \n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4216 - acc: 0.7766     \n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4186 - acc: 0.7782     \n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4201 - acc: 0.7759     \n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4184 - acc: 0.7772     \n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4173 - acc: 0.7779     \n",
      "Epoch 59/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4153 - acc: 0.7781     \n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4153 - acc: 0.7803     \n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4119 - acc: 0.7804     \n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4102 - acc: 0.7829     \n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4118 - acc: 0.7824     \n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4126 - acc: 0.7804     \n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4109 - acc: 0.7822     \n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4117 - acc: 0.7820     \n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4106 - acc: 0.7830     \n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4055 - acc: 0.7850     \n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4073 - acc: 0.7849     \n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4067 - acc: 0.7877     \n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4039 - acc: 0.7853     \n",
      "Epoch 72/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4049 - acc: 0.7847     \n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4070 - acc: 0.7856     \n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4043 - acc: 0.7863     \n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4002 - acc: 0.7894     \n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4036 - acc: 0.7867     \n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4008 - acc: 0.7884     \n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4007 - acc: 0.7885     \n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4029 - acc: 0.7855     \n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4009 - acc: 0.7876     \n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3987 - acc: 0.7895     \n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3961 - acc: 0.7896     \n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3983 - acc: 0.7905     \n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3977 - acc: 0.7894     \n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.3948 - acc: 0.7922     \n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3955 - acc: 0.7889     \n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3937 - acc: 0.7924     \n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3925 - acc: 0.7918     \n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3939 - acc: 0.7911     \n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3923 - acc: 0.7916     \n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3944 - acc: 0.7947     \n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3894 - acc: 0.7949     \n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3906 - acc: 0.7946     \n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3927 - acc: 0.7917     \n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3896 - acc: 0.7919     \n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3905 - acc: 0.7947     \n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3882 - acc: 0.7961     \n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3881 - acc: 0.7958     \n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3888 - acc: 0.7961     \n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3881 - acc: 0.7972     \n",
      "2500/2500 [==============================] - 0s     \n",
      "Epoch 1/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4986     \n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6933 - acc: 0.4973     \n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6931 - acc: 0.5008     \n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6931 - acc: 0.4974     \n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6921 - acc: 0.5088     \n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6896 - acc: 0.5152     \n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6870 - acc: 0.5221     \n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6825 - acc: 0.5298     \n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6780 - acc: 0.5354     \n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6727 - acc: 0.5413     \n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6688 - acc: 0.5477     \n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6640 - acc: 0.5505     \n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6593 - acc: 0.5555     \n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6580 - acc: 0.5566     \n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6525 - acc: 0.5628     \n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6475 - acc: 0.5648     \n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6446 - acc: 0.5671     \n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6402 - acc: 0.5707     \n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6374 - acc: 0.5738     \n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6334 - acc: 0.5751     \n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6305 - acc: 0.5776     \n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6302 - acc: 0.5766     \n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6280 - acc: 0.5780     \n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6245 - acc: 0.5799     \n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6236 - acc: 0.5801     \n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6204 - acc: 0.5834     \n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6188 - acc: 0.5826     \n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6178 - acc: 0.5848     \n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6166 - acc: 0.5840     \n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6150 - acc: 0.5851     \n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6164 - acc: 0.5848     \n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6154 - acc: 0.5863     \n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6104 - acc: 0.5866     \n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6086 - acc: 0.5892     \n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6082 - acc: 0.5898     \n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6064 - acc: 0.5905     \n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6030 - acc: 0.5920     \n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6060 - acc: 0.5904     \n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6043 - acc: 0.5911     \n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6059 - acc: 0.5908     \n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6020 - acc: 0.5937     \n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5999 - acc: 0.5940     \n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5983 - acc: 0.5946     \n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5975 - acc: 0.5940     \n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5986 - acc: 0.5944     \n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5976 - acc: 0.5962     \n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5928 - acc: 0.5983     \n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5925 - acc: 0.5990     \n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5933 - acc: 0.5983     \n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5980 - acc: 0.5974     \n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5945 - acc: 0.5990     \n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5895 - acc: 0.6016     \n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5924 - acc: 0.6007     \n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5889 - acc: 0.6020     \n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5894 - acc: 0.6010     \n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5881 - acc: 0.6008     \n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5853 - acc: 0.6036     \n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5881 - acc: 0.6020     \n",
      "Epoch 59/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5876 - acc: 0.6030     \n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5871 - acc: 0.6023     \n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5841 - acc: 0.6049     \n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5825 - acc: 0.6056     \n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5804 - acc: 0.6064     \n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5828 - acc: 0.6054     \n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5814 - acc: 0.6068     \n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5800 - acc: 0.6070     \n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5776 - acc: 0.6082     \n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5816 - acc: 0.6065     \n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.5797 - acc: 0.6086     \n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5799 - acc: 0.6079     \n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5798 - acc: 0.6075     - ETA: 1s\n",
      "Epoch 72/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5745 - acc: 0.6094     \n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5762 - acc: 0.6096     \n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5738 - acc: 0.6120     \n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5752 - acc: 0.6092     \n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5765 - acc: 0.6085     \n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5724 - acc: 0.6102     \n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5746 - acc: 0.6096     \n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5770 - acc: 0.6095     \n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5710 - acc: 0.6116     \n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5722 - acc: 0.6105     \n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5725 - acc: 0.6108     \n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5709 - acc: 0.6114     \n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5693 - acc: 0.6130     \n",
      "Epoch 85/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5692 - acc: 0.6136     \n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5703 - acc: 0.6128     \n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5702 - acc: 0.6131     \n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5674 - acc: 0.6134     \n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5706 - acc: 0.6111     \n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5662 - acc: 0.6134     \n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5701 - acc: 0.6121     \n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5659 - acc: 0.6143     \n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5667 - acc: 0.6134     \n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5708 - acc: 0.6127     \n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5661 - acc: 0.6139     \n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5687 - acc: 0.6136     \n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5635 - acc: 0.6155     \n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5648 - acc: 0.6154     \n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5629 - acc: 0.6155     \n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5643 - acc: 0.6149     \n",
      "1440/2500 [================>.............] - ETA: 0sEpoch 1/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6934 - acc: 0.5032     \n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6924 - acc: 0.5152     \n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6881 - acc: 0.5386     \n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6792 - acc: 0.5552     \n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6619 - acc: 0.5855     \n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6408 - acc: 0.6080     \n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6206 - acc: 0.6274     \n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6008 - acc: 0.6421     \n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5846 - acc: 0.6584     \n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5675 - acc: 0.6709     \n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5567 - acc: 0.6812     \n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5468 - acc: 0.6876     \n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5348 - acc: 0.6936     \n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5270 - acc: 0.6981     \n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5194 - acc: 0.7018     \n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5134 - acc: 0.7100     \n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5112 - acc: 0.7080     \n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5046 - acc: 0.7132     \n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4989 - acc: 0.7182     \n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4947 - acc: 0.7169     \n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4897 - acc: 0.7200     \n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4865 - acc: 0.7208     \n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4822 - acc: 0.7229     \n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4848 - acc: 0.7222     \n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4780 - acc: 0.7296     \n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4750 - acc: 0.7276     \n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4742 - acc: 0.7293     \n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4698 - acc: 0.7277     \n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4680 - acc: 0.7310     \n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4669 - acc: 0.7328     \n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4670 - acc: 0.7314     \n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4637 - acc: 0.7342     \n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4599 - acc: 0.7338     \n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4600 - acc: 0.7368     \n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4560 - acc: 0.7389     \n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4562 - acc: 0.7374     \n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4529 - acc: 0.7396     \n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4527 - acc: 0.7388     \n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4513 - acc: 0.7424     \n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4478 - acc: 0.7421     \n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4458 - acc: 0.7436     \n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4452 - acc: 0.7429     \n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4455 - acc: 0.7428     \n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4408 - acc: 0.7433     \n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4396 - acc: 0.7437     \n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4373 - acc: 0.7464     \n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4429 - acc: 0.7427     \n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4385 - acc: 0.7478     \n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4361 - acc: 0.7472     \n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4316 - acc: 0.7504     \n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4348 - acc: 0.7476     \n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4326 - acc: 0.7469     \n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.4326 - acc: 0.7490     \n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4292 - acc: 0.7506     \n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4307 - acc: 0.7488     \n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4317 - acc: 0.7512     \n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4286 - acc: 0.7502     \n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4247 - acc: 0.7530     \n",
      "Epoch 59/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4236 - acc: 0.7518     \n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4244 - acc: 0.7539     \n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4239 - acc: 0.7543     \n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4288 - acc: 0.7529     \n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4265 - acc: 0.7530     \n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4235 - acc: 0.7544     \n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4202 - acc: 0.7540     \n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4179 - acc: 0.7545     \n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4221 - acc: 0.7560     \n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4167 - acc: 0.7592     \n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4137 - acc: 0.7589     \n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4188 - acc: 0.7588     \n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4154 - acc: 0.7596     \n",
      "Epoch 72/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4180 - acc: 0.7597     \n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4186 - acc: 0.7576     \n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4172 - acc: 0.7563     \n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4096 - acc: 0.7619     \n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4101 - acc: 0.7602     \n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4130 - acc: 0.7583     \n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4138 - acc: 0.7582     \n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4096 - acc: 0.7618     \n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4139 - acc: 0.7596     \n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4136 - acc: 0.7601     \n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4129 - acc: 0.7616     \n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4071 - acc: 0.7629     \n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4057 - acc: 0.7643     \n",
      "Epoch 85/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4073 - acc: 0.7637     \n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4156 - acc: 0.7605     \n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4095 - acc: 0.7621     \n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4066 - acc: 0.7647     \n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4028 - acc: 0.7661     \n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4032 - acc: 0.7647     \n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4042 - acc: 0.7649     \n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4047 - acc: 0.7652     \n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4019 - acc: 0.7658     \n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4069 - acc: 0.7652     \n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3995 - acc: 0.7659     \n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4026 - acc: 0.7656     \n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4047 - acc: 0.7648     \n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4054 - acc: 0.7648     \n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4045 - acc: 0.7655     \n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4003 - acc: 0.7673     \n",
      "1280/2500 [==============>...............] - ETA: 0sEpoch 1/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6933 - acc: 0.5038     \n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6927 - acc: 0.5185     \n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6899 - acc: 0.5310     \n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6848 - acc: 0.5383     \n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6734 - acc: 0.5622     \n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6592 - acc: 0.5860     \n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6469 - acc: 0.6047     \n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6313 - acc: 0.6194     \n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6199 - acc: 0.6312     \n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6092 - acc: 0.6446     \n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6015 - acc: 0.6501     \n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5969 - acc: 0.6583     \n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5895 - acc: 0.6641     \n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5836 - acc: 0.6681     \n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5781 - acc: 0.6731     \n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5769 - acc: 0.6771     \n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5725 - acc: 0.6806     \n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5681 - acc: 0.6844     \n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5637 - acc: 0.6881     \n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5623 - acc: 0.6907     \n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5573 - acc: 0.6956     \n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5553 - acc: 0.6969     \n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5530 - acc: 0.6984     \n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5515 - acc: 0.6998     \n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5498 - acc: 0.7020     \n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5456 - acc: 0.7036     \n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5456 - acc: 0.7053     \n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5432 - acc: 0.7097     \n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5374 - acc: 0.7126     \n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5380 - acc: 0.7114     \n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5360 - acc: 0.7131     \n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5319 - acc: 0.7166     \n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5324 - acc: 0.7149     \n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5306 - acc: 0.7182     \n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5275 - acc: 0.7222     \n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5288 - acc: 0.7207     \n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.5257 - acc: 0.7229     \n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5266 - acc: 0.7206     \n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5224 - acc: 0.7266     \n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5220 - acc: 0.7268     \n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5177 - acc: 0.7284     \n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5160 - acc: 0.7300     - ETA: 1\n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5163 - acc: 0.7307     \n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5149 - acc: 0.7315     \n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5141 - acc: 0.7323     \n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5137 - acc: 0.7330     \n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5130 - acc: 0.7333     \n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5098 - acc: 0.7341     \n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5124 - acc: 0.7339     \n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5100 - acc: 0.7360     \n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5066 - acc: 0.7374     \n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5099 - acc: 0.7346     \n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5093 - acc: 0.7359     \n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5030 - acc: 0.7407     \n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5043 - acc: 0.7412     \n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5026 - acc: 0.7416     \n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5011 - acc: 0.7429     \n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5042 - acc: 0.7413     \n",
      "Epoch 59/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5013 - acc: 0.7441     \n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5004 - acc: 0.7428     \n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5008 - acc: 0.7441     \n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5002 - acc: 0.7452     \n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4971 - acc: 0.7471     \n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4973 - acc: 0.7469     \n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4962 - acc: 0.7461     \n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4968 - acc: 0.7462     \n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4951 - acc: 0.7491     \n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4941 - acc: 0.7487     \n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4928 - acc: 0.7500     \n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4904 - acc: 0.7520     \n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4917 - acc: 0.7503     \n",
      "Epoch 72/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4925 - acc: 0.7512     \n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4886 - acc: 0.7527     \n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4905 - acc: 0.7518     \n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4895 - acc: 0.7523     \n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4866 - acc: 0.7554     \n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4882 - acc: 0.7536     \n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4863 - acc: 0.7548     \n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4861 - acc: 0.7544     \n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4875 - acc: 0.7542     \n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4857 - acc: 0.7555     \n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4859 - acc: 0.7559     \n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4837 - acc: 0.7572     \n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4822 - acc: 0.7568     \n",
      "Epoch 85/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4866 - acc: 0.7548     \n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4827 - acc: 0.7576     \n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4836 - acc: 0.7569     \n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4863 - acc: 0.7572     \n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4840 - acc: 0.7571     \n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4774 - acc: 0.7612     \n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4801 - acc: 0.7591     \n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4796 - acc: 0.7597     \n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4813 - acc: 0.7595     \n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4765 - acc: 0.7612     \n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4839 - acc: 0.7574     \n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4822 - acc: 0.7587     \n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4806 - acc: 0.7591     \n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4765 - acc: 0.7635     \n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4775 - acc: 0.7620     \n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4773 - acc: 0.7623     \n",
      "1504/2500 [=================>............] - ETA: 0sEpoch 1/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6933 - acc: 0.5004     \n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6929 - acc: 0.5084     \n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6909 - acc: 0.5276     \n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6865 - acc: 0.5424     \n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6769 - acc: 0.5670     \n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6586 - acc: 0.5952     \n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6374 - acc: 0.6167     \n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6149 - acc: 0.6372     \n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5989 - acc: 0.6530     \n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5815 - acc: 0.6689     \n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5692 - acc: 0.6778     \n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5561 - acc: 0.6907     \n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5475 - acc: 0.6982     \n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5387 - acc: 0.7044     \n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5296 - acc: 0.7110     \n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5222 - acc: 0.7170     \n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5156 - acc: 0.7204     \n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5091 - acc: 0.7264     \n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5036 - acc: 0.7331     \n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5055 - acc: 0.7309     \n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.4974 - acc: 0.7378     \n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4918 - acc: 0.7390     \n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4884 - acc: 0.7432     \n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4829 - acc: 0.7448     \n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4806 - acc: 0.7485     \n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4762 - acc: 0.7524     \n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4774 - acc: 0.7510     \n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4706 - acc: 0.7543     \n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4692 - acc: 0.7557     \n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4667 - acc: 0.7560     \n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4644 - acc: 0.7600     \n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4650 - acc: 0.7581     \n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4619 - acc: 0.7607     \n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4552 - acc: 0.7618     \n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4583 - acc: 0.7628     \n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4517 - acc: 0.7676     \n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4509 - acc: 0.7664     \n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4478 - acc: 0.7677     \n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4510 - acc: 0.7701     \n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4487 - acc: 0.7684     \n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4458 - acc: 0.7699     \n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4463 - acc: 0.7710     \n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4438 - acc: 0.7715     \n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4375 - acc: 0.7744     \n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4404 - acc: 0.7737     \n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4401 - acc: 0.7741     \n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4377 - acc: 0.7733     \n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4357 - acc: 0.7752     \n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4339 - acc: 0.7750     \n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4346 - acc: 0.7770     \n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4348 - acc: 0.7755     \n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4302 - acc: 0.7773     \n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4301 - acc: 0.7790     \n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4292 - acc: 0.7797     \n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4247 - acc: 0.7810     \n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4272 - acc: 0.7816     \n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4242 - acc: 0.7823     \n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4278 - acc: 0.7804     \n",
      "Epoch 59/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4243 - acc: 0.7823     \n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4246 - acc: 0.7809     \n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4249 - acc: 0.7807     \n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4207 - acc: 0.7842     \n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4246 - acc: 0.7836     \n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4213 - acc: 0.7837     \n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4164 - acc: 0.7862     \n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4187 - acc: 0.7854     \n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4204 - acc: 0.7854     \n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4167 - acc: 0.7843     \n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4156 - acc: 0.7888     \n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4208 - acc: 0.7856     \n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4178 - acc: 0.7873     \n",
      "Epoch 72/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4148 - acc: 0.7893     \n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4191 - acc: 0.7856     \n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4187 - acc: 0.7845     \n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4102 - acc: 0.7891     \n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4070 - acc: 0.7926     \n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4112 - acc: 0.7900     \n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4082 - acc: 0.7914     \n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4148 - acc: 0.7886     \n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4109 - acc: 0.7901     \n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4081 - acc: 0.7935     \n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4020 - acc: 0.7952     \n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4064 - acc: 0.7926     \n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4038 - acc: 0.7956     - ETA:\n",
      "Epoch 85/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4073 - acc: 0.7921     \n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4044 - acc: 0.7929     \n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4058 - acc: 0.7912     \n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4026 - acc: 0.7944     \n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4079 - acc: 0.7940     \n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4035 - acc: 0.7949     \n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3993 - acc: 0.7952     \n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4018 - acc: 0.7960     \n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4016 - acc: 0.7962     \n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4022 - acc: 0.7950     \n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4020 - acc: 0.7968     \n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4025 - acc: 0.7963     \n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3928 - acc: 0.8018     \n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3992 - acc: 0.7984     \n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3952 - acc: 0.7992     \n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3952 - acc: 0.8008     \n",
      "1440/2500 [================>.............] - ETA: 0sEpoch 1/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6931 - acc: 0.5075     \n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6921 - acc: 0.5166     \n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6883 - acc: 0.5371     \n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6789 - acc: 0.5641     \n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.6627 - acc: 0.5909     \n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6450 - acc: 0.6144     \n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6250 - acc: 0.6325     \n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6062 - acc: 0.6534     \n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5889 - acc: 0.6650     \n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5728 - acc: 0.6739     \n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5621 - acc: 0.6826     \n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5493 - acc: 0.6901     \n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5383 - acc: 0.6985     \n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5299 - acc: 0.7047     \n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5245 - acc: 0.7085     \n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5179 - acc: 0.7137     \n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5141 - acc: 0.7154     \n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5062 - acc: 0.7184     \n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5032 - acc: 0.7224     \n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4960 - acc: 0.7264     \n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4916 - acc: 0.7280     \n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4891 - acc: 0.7281     \n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4855 - acc: 0.7321     \n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4840 - acc: 0.7341     \n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4811 - acc: 0.7364     \n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4743 - acc: 0.7410     \n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4726 - acc: 0.7381     \n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4724 - acc: 0.7404     \n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4697 - acc: 0.7418     \n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4631 - acc: 0.7448     \n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4626 - acc: 0.7463     \n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4594 - acc: 0.7464     \n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4635 - acc: 0.7478     \n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4573 - acc: 0.7489     \n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4541 - acc: 0.7499     \n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4559 - acc: 0.7509     \n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4515 - acc: 0.7526     \n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4504 - acc: 0.7541     \n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4502 - acc: 0.7546     \n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4458 - acc: 0.7550     \n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4450 - acc: 0.7566     \n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4447 - acc: 0.7560     \n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4447 - acc: 0.7550     \n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4410 - acc: 0.7549     \n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4363 - acc: 0.7611     \n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4399 - acc: 0.7570     \n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4365 - acc: 0.7600     \n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4334 - acc: 0.7624     \n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4340 - acc: 0.7644     \n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4311 - acc: 0.7634     \n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4304 - acc: 0.7649     \n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4297 - acc: 0.7653     \n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4297 - acc: 0.7656     \n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4257 - acc: 0.7657     \n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4243 - acc: 0.7667     \n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4247 - acc: 0.7709     \n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4218 - acc: 0.7711     \n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4213 - acc: 0.7688     \n",
      "Epoch 59/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4189 - acc: 0.7716     \n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4203 - acc: 0.7695     \n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4189 - acc: 0.7716     \n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4198 - acc: 0.7716     \n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4186 - acc: 0.7706     \n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4184 - acc: 0.7734     \n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4189 - acc: 0.7720     \n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4124 - acc: 0.7756     \n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4100 - acc: 0.7786     \n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4129 - acc: 0.7742     \n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4118 - acc: 0.7768     \n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4102 - acc: 0.7757     \n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4091 - acc: 0.7783     \n",
      "Epoch 72/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4077 - acc: 0.7772     \n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4087 - acc: 0.7778     \n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4058 - acc: 0.7789     \n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4020 - acc: 0.7800     \n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4082 - acc: 0.7763     \n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4063 - acc: 0.7775     \n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4061 - acc: 0.7796     \n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4000 - acc: 0.7833     \n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4037 - acc: 0.7803     \n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4061 - acc: 0.7790     \n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4004 - acc: 0.7831     \n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3995 - acc: 0.7835     \n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3974 - acc: 0.7842     \n",
      "Epoch 85/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3989 - acc: 0.7835     \n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3971 - acc: 0.7856     \n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3979 - acc: 0.7846     \n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3975 - acc: 0.7836     \n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.3975 - acc: 0.7841     \n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3959 - acc: 0.7874     \n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3962 - acc: 0.7868     \n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3979 - acc: 0.7838     \n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3935 - acc: 0.7862     \n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3945 - acc: 0.7883     \n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3955 - acc: 0.7869     \n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3927 - acc: 0.7874     \n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3897 - acc: 0.7895     \n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3905 - acc: 0.7871     \n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3943 - acc: 0.7871     \n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3969 - acc: 0.7877     \n",
      "1344/2500 [===============>..............] - ETA: 0sEpoch 1/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6932 - acc: 0.4952     \n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5000     \n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4964     \n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4991     \n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5002     \n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4956     \n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4983     \n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4951     \n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4977     \n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5008     \n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4950     \n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4974     \n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6931 - acc: 0.5040     \n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4976     \n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4972     \n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5024     \n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4972     \n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4968     \n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4982     \n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4973     \n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4965     \n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4974     \n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4976     \n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5000     \n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4919     \n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4963     \n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5018     \n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4988     \n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5026     \n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5026     \n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4997     \n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4988     \n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4946     \n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6931 - acc: 0.5041     \n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5021     \n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4981     \n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4981     \n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4941     \n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4982     \n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4953     \n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4944     \n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4982     \n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4952     \n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4982     \n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4998     \n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4997     \n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4991     \n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4923     \n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4979     \n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4975     \n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5000     \n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - ETA: 0s - loss: 0.6932 - acc: 0.495 - 1s - loss: 0.6932 - acc: 0.4958     \n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5016     \n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4993     \n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4962     \n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5008     \n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5006     \n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4968     \n",
      "Epoch 59/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5001     \n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4984     \n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5013     \n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4974     \n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4971     \n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4952     \n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4970     \n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4994     \n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4980     \n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4993     \n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4984     \n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4964     \n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4993     \n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4954     \n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4992     \n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4977     \n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4990     \n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4950     \n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5000     \n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5008     \n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4959     \n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4962     \n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5005     \n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4980     \n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4963     \n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4961     \n",
      "Epoch 85/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4977     \n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4983     \n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5000     \n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5004     \n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4943     \n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4973     \n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4996     \n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4998     \n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4968     \n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4978     \n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5018     \n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4998     \n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4997     \n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4952     \n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.5020     \n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6932 - acc: 0.4987     \n",
      "1664/2500 [==================>...........] - ETA: 0sEpoch 1/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6934 - acc: 0.4968     \n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6930 - acc: 0.5062     \n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6922 - acc: 0.5140     \n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6884 - acc: 0.5356     \n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6794 - acc: 0.5597     \n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6647 - acc: 0.5880     \n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6476 - acc: 0.6102     \n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6313 - acc: 0.6336     \n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6137 - acc: 0.6517     \n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5995 - acc: 0.6683     \n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5864 - acc: 0.6782     \n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5745 - acc: 0.6920     \n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5661 - acc: 0.6984     \n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5582 - acc: 0.7060     \n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5520 - acc: 0.7092     \n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5451 - acc: 0.7167     \n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5386 - acc: 0.7192     \n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5332 - acc: 0.7252     \n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5286 - acc: 0.7310     \n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5240 - acc: 0.7334     \n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5213 - acc: 0.7336     \n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5153 - acc: 0.7420     \n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5134 - acc: 0.7405     \n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - ETA: 0s - loss: 0.5103 - acc: 0.742 - 1s - loss: 0.5103 - acc: 0.7425     \n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5042 - acc: 0.7477     \n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5021 - acc: 0.7484     \n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5017 - acc: 0.7481     \n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4963 - acc: 0.7528     \n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4919 - acc: 0.7573     \n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4925 - acc: 0.7544     \n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4892 - acc: 0.7577     \n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4872 - acc: 0.7601     \n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4861 - acc: 0.7596     \n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4837 - acc: 0.7643     \n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4812 - acc: 0.7624     \n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4809 - acc: 0.7623     \n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4798 - acc: 0.7640     \n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4769 - acc: 0.7667     \n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4758 - acc: 0.7695     \n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4740 - acc: 0.7677     \n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4741 - acc: 0.7683     \n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4723 - acc: 0.7708     \n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4693 - acc: 0.7712     \n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4710 - acc: 0.7710     \n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4680 - acc: 0.7736     \n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4683 - acc: 0.7703     \n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4652 - acc: 0.7728     \n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4610 - acc: 0.7759     \n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4629 - acc: 0.7753     \n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4616 - acc: 0.7752     \n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4579 - acc: 0.7782     \n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4546 - acc: 0.7803     \n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4561 - acc: 0.7784     \n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4542 - acc: 0.7810     \n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.4539 - acc: 0.7809     \n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4546 - acc: 0.7803     \n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4525 - acc: 0.7818     \n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4537 - acc: 0.7814     \n",
      "Epoch 59/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4496 - acc: 0.7831     \n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4455 - acc: 0.7854     \n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4486 - acc: 0.7845     \n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4466 - acc: 0.7848     \n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4456 - acc: 0.7856     \n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4420 - acc: 0.7875     \n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4438 - acc: 0.7879     \n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4444 - acc: 0.7851     \n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4429 - acc: 0.7883     \n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4416 - acc: 0.7874     \n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4413 - acc: 0.7890     \n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4420 - acc: 0.7887     \n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4403 - acc: 0.7890     \n",
      "Epoch 72/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4365 - acc: 0.7919     \n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4413 - acc: 0.7882     \n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4363 - acc: 0.7913     \n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4357 - acc: 0.7936     \n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4363 - acc: 0.7905     \n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4376 - acc: 0.7925     \n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4331 - acc: 0.7937     \n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4346 - acc: 0.7923     \n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4324 - acc: 0.7940     \n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4363 - acc: 0.7912     \n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4327 - acc: 0.7942     \n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4301 - acc: 0.7948     \n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4285 - acc: 0.7975     \n",
      "Epoch 85/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4300 - acc: 0.7949     \n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4290 - acc: 0.7943     \n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4289 - acc: 0.7940     \n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4289 - acc: 0.7954     \n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4291 - acc: 0.7972     \n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4311 - acc: 0.7936     \n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4290 - acc: 0.7956     \n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4264 - acc: 0.7964     \n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4244 - acc: 0.7985     \n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4235 - acc: 0.7973     \n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4243 - acc: 0.7989     \n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4243 - acc: 0.7994     \n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4200 - acc: 0.8012     \n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4240 - acc: 0.7979     \n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4240 - acc: 0.7986     \n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4191 - acc: 0.8011     \n",
      "1600/2500 [==================>...........] - ETA: 0sEpoch 1/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6931 - acc: 0.5089     \n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6918 - acc: 0.5189     \n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6883 - acc: 0.5370     \n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6807 - acc: 0.5488     \n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6659 - acc: 0.5739     \n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6472 - acc: 0.6022     \n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6259 - acc: 0.6259     \n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6057 - acc: 0.6446     \n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5896 - acc: 0.6584     \n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5746 - acc: 0.6720     \n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5635 - acc: 0.6796     \n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5542 - acc: 0.6883     \n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5443 - acc: 0.6944     \n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5367 - acc: 0.7003     \n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5313 - acc: 0.7050     \n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5264 - acc: 0.7070     \n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5195 - acc: 0.7119     \n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5174 - acc: 0.7140     \n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5110 - acc: 0.7164     \n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5067 - acc: 0.7203     \n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5045 - acc: 0.7211     \n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5011 - acc: 0.7246     \n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4987 - acc: 0.7245     \n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4931 - acc: 0.7273     \n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4930 - acc: 0.7268     \n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4919 - acc: 0.7285     \n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4852 - acc: 0.7335     \n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4866 - acc: 0.7308     \n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4797 - acc: 0.7352     \n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4783 - acc: 0.7374     \n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4763 - acc: 0.7400     \n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4764 - acc: 0.7394     \n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4727 - acc: 0.7399     \n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4701 - acc: 0.7414     \n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4694 - acc: 0.7425     \n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4700 - acc: 0.7408     \n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4673 - acc: 0.7418     \n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4694 - acc: 0.7425     \n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.4659 - acc: 0.7451     \n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4662 - acc: 0.7452     \n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4566 - acc: 0.7480     \n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4598 - acc: 0.7479     \n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4586 - acc: 0.7480     \n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4577 - acc: 0.7490     \n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4562 - acc: 0.7511     \n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4508 - acc: 0.7515     \n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4500 - acc: 0.7536     \n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4516 - acc: 0.7520     \n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4518 - acc: 0.7513     \n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4525 - acc: 0.7501     \n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4458 - acc: 0.7541     \n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4501 - acc: 0.7517     \n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4500 - acc: 0.7514     \n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4481 - acc: 0.7516     \n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4461 - acc: 0.7536     \n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4413 - acc: 0.7565     \n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4401 - acc: 0.7566     \n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4407 - acc: 0.7564     \n",
      "Epoch 59/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4443 - acc: 0.7524     \n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4406 - acc: 0.7562     \n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4421 - acc: 0.7555     \n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4454 - acc: 0.7538     \n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4371 - acc: 0.7576     \n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4371 - acc: 0.7581     \n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4382 - acc: 0.7572     \n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4395 - acc: 0.7572     \n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4355 - acc: 0.7583     \n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4345 - acc: 0.7586     \n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4319 - acc: 0.7611     \n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4325 - acc: 0.7598     \n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4323 - acc: 0.7612     \n",
      "Epoch 72/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4355 - acc: 0.7579     \n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4299 - acc: 0.7620     \n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4291 - acc: 0.7619     \n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4308 - acc: 0.7617     \n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4301 - acc: 0.7613     \n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4283 - acc: 0.7608     \n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4299 - acc: 0.7613     \n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4284 - acc: 0.7616     \n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4290 - acc: 0.7606     \n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4262 - acc: 0.7638     \n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4244 - acc: 0.7636     \n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4252 - acc: 0.7626     \n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4249 - acc: 0.7647     \n",
      "Epoch 85/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4234 - acc: 0.7637     \n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4208 - acc: 0.7655     \n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4235 - acc: 0.7645     \n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4233 - acc: 0.7644     \n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4199 - acc: 0.7654     \n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4179 - acc: 0.7660     \n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4192 - acc: 0.7660     \n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4220 - acc: 0.7652     \n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4173 - acc: 0.7659     \n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4156 - acc: 0.7679     \n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4188 - acc: 0.7663     \n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4191 - acc: 0.7663     \n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4215 - acc: 0.7647     \n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4210 - acc: 0.7647     \n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4140 - acc: 0.7673     \n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4136 - acc: 0.7684     \n",
      "1632/2500 [==================>...........] - ETA: 0s Epoch 1/100\n",
      "22500/22500 [==============================] - 2s - loss: 0.6934 - acc: 0.4996     \n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6930 - acc: 0.5025     \n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6927 - acc: 0.5126     \n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6893 - acc: 0.5344     \n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6828 - acc: 0.5538     \n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6704 - acc: 0.5787     \n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6527 - acc: 0.6023     \n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6315 - acc: 0.6266     \n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.6146 - acc: 0.6430     \n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5971 - acc: 0.6595     \n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5823 - acc: 0.6678     \n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5681 - acc: 0.6799     \n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5558 - acc: 0.6908     \n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5463 - acc: 0.6997     \n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5373 - acc: 0.7076     \n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5313 - acc: 0.7126     \n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5242 - acc: 0.7179     \n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5182 - acc: 0.7189     \n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5107 - acc: 0.7242     \n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5075 - acc: 0.7262     \n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.5052 - acc: 0.7280     \n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4990 - acc: 0.7332     \n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s - loss: 0.4998 - acc: 0.7318     \n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4921 - acc: 0.7356     \n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4886 - acc: 0.7398     \n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4909 - acc: 0.7411     \n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4846 - acc: 0.7428     \n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4834 - acc: 0.7451     \n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4788 - acc: 0.7482     \n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4728 - acc: 0.7513     \n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4707 - acc: 0.7532     \n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4719 - acc: 0.7525     \n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4682 - acc: 0.7533     \n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4688 - acc: 0.7534     \n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4646 - acc: 0.7572     \n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4696 - acc: 0.7569     \n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4591 - acc: 0.7611     \n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4593 - acc: 0.7613     \n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4603 - acc: 0.7615     \n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4553 - acc: 0.7636     \n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4541 - acc: 0.7651     \n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4508 - acc: 0.7671     \n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4509 - acc: 0.7683     \n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4516 - acc: 0.7669     \n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4464 - acc: 0.7698     \n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4465 - acc: 0.7676     \n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4416 - acc: 0.7721     \n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4444 - acc: 0.7710     \n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4434 - acc: 0.7727     \n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4381 - acc: 0.7741     \n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4362 - acc: 0.7763     \n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4338 - acc: 0.7778     \n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4393 - acc: 0.7757     \n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4343 - acc: 0.7768     \n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4345 - acc: 0.7758     \n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4352 - acc: 0.7779     \n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4344 - acc: 0.7784     \n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4293 - acc: 0.7799     \n",
      "Epoch 59/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4304 - acc: 0.7793     \n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4274 - acc: 0.7810     \n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4272 - acc: 0.7818     \n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4261 - acc: 0.7808     \n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4263 - acc: 0.7833     \n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4230 - acc: 0.7840     \n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4233 - acc: 0.7835     \n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4227 - acc: 0.7829     \n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4191 - acc: 0.7869     \n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4224 - acc: 0.7852     \n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4206 - acc: 0.7848     \n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4186 - acc: 0.7871     \n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4196 - acc: 0.7873     \n",
      "Epoch 72/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4169 - acc: 0.7885     \n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4130 - acc: 0.7887     \n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4140 - acc: 0.7900     \n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4130 - acc: 0.7901     \n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4149 - acc: 0.7881     \n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4135 - acc: 0.7893     \n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4113 - acc: 0.7905     \n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4130 - acc: 0.7918     \n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4107 - acc: 0.7927     \n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4120 - acc: 0.7904     \n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4062 - acc: 0.7928     \n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4129 - acc: 0.7904     \n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4111 - acc: 0.7920     \n",
      "Epoch 85/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4067 - acc: 0.7948     \n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4083 - acc: 0.7937     \n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4063 - acc: 0.7948     \n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4038 - acc: 0.7957     \n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4014 - acc: 0.7991     \n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4071 - acc: 0.7970     \n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4036 - acc: 0.7990     \n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4040 - acc: 0.7967     - ETA: 1\n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4001 - acc: 0.7990     \n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4032 - acc: 0.7965     \n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4029 - acc: 0.7970     \n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4002 - acc: 0.7981     \n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.4033 - acc: 0.7963     \n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3997 - acc: 0.7982     \n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3954 - acc: 0.8011     \n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 1s - loss: 0.3995 - acc: 0.7973     \n",
      "1856/2500 [=====================>........] - ETA: 0s Accuracy mean: 0.50924\n",
      "Accuracy variance: 0.00984755807294\n"
     ]
    }
   ],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 100)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 50.696000 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 53.404000 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 51.652000 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 54.508000 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 50.416000 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
